{"version":3,"file":"index.js","sources":["src/utils/curry.ts","src/utils/exec.ts","src/utils/match.ts","src/utils/replace.ts","src/utils/split.ts","src/utils/matches.ts","src/utils/clearSource.ts","src/utils/compose.ts","src/utils/equals.ts","src/utils/map.ts","src/parsers/captureCodeBlock.ts","src/utils/startsWith.ts","src/parsers/captureNewLine.ts","src/parsers/captureHeading.ts","src/parsers/captureBlockquote.ts","src/parsers/captureTable.ts","src/parsers/captureHR.ts","src/parsers/captureParagraph.ts","src/parsers/captureList.ts","src/parsers/captureEscape.ts","src/parsers/captureLinks.ts","src/parsers/captureStrong.ts","src/parsers/captureEm.ts","src/parsers/captureStrikethrough.ts","src/parsers/captureCode.ts","src/parsers/captureLinebreak.ts","src/parsers/captureText.ts","src/core/MDJ.ts","src/index.ts"],"sourcesContent":["// Yep, interfaces are stolen from ramda types\ninterface CurriedFunction2<T1, T2, R> {\n  (t1: T1): (t2: T2) => R\n  (t1: T1, t2: T2): R\n}\n\ninterface CurriedFunction3<T1, T2, T3, R> {\n  (t1: T1): CurriedFunction2<T2, T3, R>\n  (t1: T1, t2: T2): (t3: T3) => R\n  (t1: T1, t2: T2, t3: T3): R\n}\n\ninterface CurriedFunction4<T1, T2, T3, T4, R> {\n  (t1: T1): CurriedFunction3<T2, T3, T4, R>\n  (t1: T1, t2: T2): CurriedFunction2<T3, T4, R>\n  (t1: T1, t2: T2, t3: T3): (t4: T4) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4): R\n}\n\ninterface CurriedFunction5<T1, T2, T3, T4, T5, R> {\n  (t1: T1): CurriedFunction4<T2, T3, T4, T5, R>\n  (t1: T1, t2: T2): CurriedFunction3<T3, T4, T5, R>\n  (t1: T1, t2: T2, t3: T3): CurriedFunction2<T4, T5, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4): (t5: T5) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5): R\n}\n\ninterface CurriedFunction6<T1, T2, T3, T4, T5, T6, R> {\n  (t1: T1): CurriedFunction5<T2, T3, T4, T5, T6, R>\n  (t1: T1, t2: T2): CurriedFunction4<T3, T4, T5, T6, R>\n  (t1: T1, t2: T2, t3: T3): CurriedFunction3<T4, T5, T6, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4): CurriedFunction2<T5, T6, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5): (t6: T6) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5, t6: T6): R\n}\n\ninterface Curry {\n  <T1, T2, TResult>(fn: (a: T1, b: T2) => TResult, args?: any): CurriedFunction2<T1,T2, TResult>\n  <T1, T2, T3, TResult>(fn: (a: T1, b: T2, c: T3) => TResult, args?: any): CurriedFunction3<T1,T2, T3, TResult>\n  <T1, T2, T3, T4, TResult>(fn: (a: T1, b: T2, c: T3, d: T4) => TResult, args?: any): CurriedFunction4<T1,T2, T3, T4, TResult>\n  <T1, T2, T3, T4, T5, TResult>(fn: (a: T1, b: T2, c: T3, d: T4, e: T5) => TResult, args?: any): CurriedFunction5<T1,T2, T3, T4, T5, TResult>\n  <T1, T2, T3, T4, T5, T6, TResult>(fn: (a: T1, b: T2, c: T3, d: T4, e: T5, f: T6) => TResult, args?: any): CurriedFunction6<T1,T2, T3, T4, T5, T6, TResult>\n  (fn: Function): Function\n}\n\nconst curry: Curry = function() {\n  const fn: Function = arguments[0]\n  const length = fn.length\n\n  const inner = function() {\n    let args = Array.prototype.slice.call(arguments)\n\n    if (args.length >= length) {\n      return fn.apply(null, args)\n    } else {\n      return inner.bind.apply(inner, [null].concat(args))\n    }\n  }\n\n  return inner.bind.apply(inner, [null].concat(Array.prototype.slice.call(arguments, 1)))\n}\n\nexport { curry }\n","import { curry } from 'utils'\n\nconst exec = curry((regExp: RegExp, input: string): string[] | null => regExp.exec(input))\n\nexport { exec }\n\n","import { curry } from 'utils'\n\nconst match = curry((regExp: RegExp, input: string) => input.match(regExp) || [])\n\nexport { match }\n","import { curry } from 'utils'\n\nconst replace = curry((from: string | RegExp, to: string, input: string) => input.replace(from, to))\n\nexport { replace }\n","import { curry } from 'utils'\n\nconst split = curry((regExp: RegExp | string, input: string): string[] => input.split(regExp))\n\nexport { split }\n","import { curry } from 'utils'\n\nconst matches = curry((withWhat: RegExp, what: string) => withWhat.test(what))\n\nexport { matches }\n","const clearSource = (input: string) => input.replace(/\\r\\n|\\r/g, '\\n')\n  .replace(/\\t/g, '    ')\n  .replace(/\\u00a0/g, ' ')\n  .replace(/\\u2424/g, '\\n')\n  .replace(/^ +$/gm, '')\n\nexport { clearSource }\n","interface Compose {\n  <V0, T1>(fn0: (x0: V0) => T1): (x0: V0) => T1;\n  <V0, V1, T1>(fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T1;\n  <V0, V1, V2, T1>(fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T1;\n\n  <V0, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0) => T1): (x0: V0) => T2;\n  <V0, V1, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T2;\n  <V0, V1, V2, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T2;\n\n  <V0, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T3;\n  <V0, V1, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T3;\n  <V0, V1, V2, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T3;\n\n  <V0, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T4;\n  <V0, V1, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T4;\n  <V0, V1, V2, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T4;\n\n  <V0, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T5;\n  <V0, V1, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T5;\n  <V0, V1, V2, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T5;\n\n  <V0, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T6;\n  <V0, V1, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T6;\n  <V0, V1, V2, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T6;\n}\n\nconst compose: Compose = function () {\n  const fns = Array.prototype.slice.call(arguments)\n  const l = fns.length - 1\n\n  return function(arg: any) {\n    let result = arg\n\n    for (let i = l; i >= 0; i -= 1) {\n      result = fns[i](result)\n    }\n\n    return result\n  }\n}\n\nexport { compose }\n","import { curry } from 'utils'\n\nconst equals = curry((a: any, b: any): boolean => a === b)\n\nexport { equals }\n","import { curry } from 'utils'\n\ninterface Map {\n  <V, R>(fn: (x0: V, x1: number, x2: V[]) => R): (input: V[]) => R[]\n  <V, R>(fn: (x0: V, x1: number, x2: V[]) => R, input: V[]): R[]\n}\n\nconst map: Map = curry(<V, R>(fn: (x0: V, x1: number, x2: V[]) => R , input: V[]) => {\n  const result = new Array(input.length)\n\n  for (let i = 0; i < input.length; i += 1) {\n    result[i] = fn(input[i], i, input)\n  }\n\n  return result\n})\n\nexport { map }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeCodeBlock } from 'models'\n\nconst execCodeNormal = exec(/^( {4}[^\\n]+\\n*)+/)\nconst clearCode = replace(/^ {4}/gm, '')\nconst execCodeFence = exec(/^ *(`{3,}|~{3,})[ \\.]*(\\S+)? *\\n([\\s\\S]*?)\\s*\\1 *(?:\\n+|$)/)\n\nconst captureCodeNormal = (source: string): Parsed<NodeCodeBlock> | null => {\n  if (source[0] !== '`') {\n    return null\n  }\n\n  const result = execCodeNormal(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'codeblock',\n      language: '',\n      value: clearCode(capture)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst captureCodeFence = (source: string): Parsed<NodeCodeBlock> | null => {\n  const result = execCodeFence(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const language = result[2]\n  const value = result[3]\n\n  return {\n    token: {\n      type: 'codeblock',\n      language,\n      value\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst captureCodeBlock = (source: string): Parsed<NodeCodeBlock> | null =>\n  captureCodeNormal(source) || captureCodeFence(source)\nexport { captureCodeBlock }\n","import { curry } from 'utils'\n\nconst startsWith = curry((what: string, where: string) => where.indexOf(what) === 0)\n\nexport { startsWith }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeSpace } from 'models'\n\nconst execNewLine = exec(/^\\n+/)\n\nconst captureNewLine = (source: string): Parsed<NodeSpace> | null => {\n  const result = execNewLine(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: { type: 'space' },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureNewLine }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeHeading, Tokenizer } from 'models'\n\nconst execHeading = exec(/^ *(#{1,6}) +([^\\n]+?) *#* *(?:\\n+|$)/)\nconst execLHeading = exec(/^([^\\n]+)\\n *([=-]){2,} *(?:\\n+|$)/)\nconst getLevel = (input: string): number => {\n  if (input[0] === '#') {\n    return input.length\n  }\n\n  return input === '=' ? 1 : 2\n}\n\nconst captureHeading = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeHeading> | null => {\n  const result = (source[0] === '#' && execHeading(source)) || execLHeading(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const level = result[1]\n  const rawValue = result[2]\n\n  return {\n    token: {\n      type: 'heading',\n      level: getLevel(level),\n      children: inlineLexer(rawValue)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\n\nexport { captureHeading }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeBlockquote, Tokenizer, NodeParagraph } from 'models'\n\nconst execBlockquote = exec(/^( *>[^\\n]+(\\n(?! *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +[\"(]([^\\n]+)[\")])? *(?:\\n+|$))[^\\n]+)*\\n*)+/)\nconst clearBlockquote = replace(/^ *> ?/gm, '')\nconst captureBlockquote = (source: string, tokenize: Tokenizer): Parsed<NodeBlockquote> | null => {\n  if (source[0] !== '>') {\n    return null\n  }\n\n  const result = execBlockquote(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  let children = tokenize(clearBlockquote(capture))\n\n  if (children.length === 1 && children[0].type === 'paragraph') {\n    children = (children[0] as NodeParagraph).children\n  }\n\n  return {\n    token: {\n      type: 'blockquote',\n      children: tokenize(clearBlockquote(capture))\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureBlockquote }\n","import { exec, matches, replace, compose, map, split } from 'utils'\n\nimport { Parsed, NodeTable, Tokenizer, NodeItem } from 'models'\n\nconst rowSep = / *\\| */\nconst removeHeaderBounds = replace(/^ *| *\\| *$/g, '')\nconst removeCellBounds = replace(/^ *\\| *| *\\| *$/g, '')\nconst removeRowBounds = replace(/^ *|\\| *$/g, '')\nconst removeLastLineBreak = replace(/\\n$/, ' ')\nconst removeLastBounds = replace(/(?: *\\| *)?\\n$/, '')\nconst splitByLineBreak = split('\\n')\nconst isRight = matches(/^ *-+: *$/)\nconst isCenter = matches(/^ *:-+: *$/)\n\nconst getTableHeader = (source: string): string[] => removeHeaderBounds(source).split(rowSep).map(item => item.trim())\nconst getTableRow = compose(split(rowSep), removeCellBounds)\nconst getCellAlign = (input: string): string | null => {\n  if (isRight(input)) {\n    return 'right'\n  } else if (isCenter(input)) {\n    return 'center'\n  } else {\n    return 'left'\n  }\n}\nconst getTableAlign = (source: string): Array<string | null> => removeRowBounds(source).split(rowSep).map(getCellAlign)\nconst getNormalCells = (lexer: Tokenizer, cells: string): NodeItem[][][] =>\n  compose(map(compose(map(lexer), getTableRow)), splitByLineBreak, removeLastBounds)(cells)\nconst getNPCells = (lexer: Tokenizer, cells: string): NodeItem[][][] =>\n  compose(map(compose(map(lexer), split(rowSep))), splitByLineBreak, removeLastLineBreak)(cells)\n\nconst execNPTable = exec(/^ *(\\S.*\\|.*)\\n *([-:]+ *\\|[-| :]*)\\n((?:.*\\|.*(?:\\n|$))*)\\n*/)\nconst execTableNormal = exec(/^ *\\|(.+)\\n *\\|( *[-:]+[-| :]*)\\n((?: *\\|.*(?:\\n|$))*)\\n*/)\n\nconst captureTable = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeTable> | null => {\n  let result = execNPTable(source)\n  let isNP = true\n\n  if (!result) {\n    result = execTableNormal(source)\n    isNP = false\n  }\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const header = result[1]\n  const align = result[2]\n  const cells = result[3]\n\n  if (!capture) {\n    return null\n  }\n\n  return {\n    token: {\n      type: 'table',\n      header: getTableHeader(header),\n      align: getTableAlign(align),\n      cells: isNP ? getNPCells(inlineLexer, cells) : getNormalCells(inlineLexer, cells)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureTable }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeHR } from 'models'\n\nconst execHR = exec(/^ *(?:\\*{3,}|-{3,}|_{3,}) *(?:\\n+|$)/)\n\nconst captureHR = (source: string): Parsed<NodeHR> | null => {\n  const result = execHR(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: { type: 'hr' },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureHR }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeParagraph, Tokenizer } from 'models'\n\nconst execParagraph = exec(/^((?:[^\\n]+\\n?)+)\\n*/)\nconst removeLastLineBreak = replace(/\\n$/, ' ')\n\nconst captureParagraph = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeParagraph> | null => {\n  const result = execParagraph(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const rawValue = result[1]\n\n  return {\n    token: {\n      type: 'paragraph',\n      children: inlineLexer(removeLastLineBreak(rawValue))\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureParagraph }\n","import { exec, match, replace, compose } from 'utils'\n\nimport { Parsed, NodeList, NodeListItem, Tokenizer, NodeParagraph } from 'models'\nimport {  } from '../utils/match'\n\nconst execList = exec(/^( *)((?:[*+-]|\\d+\\.)) [\\s\\S]+?(?:\\n+(?=\\1?(?:[-*_] *){3,}(?:\\n+|$))|\\n+(?= *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +[\"(]([^\\n]+)[\")])? *(?:\\n+|$))|\\n{2,}(?! )(?!\\1(?:[*+-]|\\d+\\.) )\\n*|\\s*$)/)\nconst matchItems = match(/^( *)((?:[*+-]|\\d+\\.)) [^\\n]*(?:\\n(?!\\1(?:[*+-]|\\d+\\.) )[^\\n]*)*/gm)\nconst removeBullets = replace(/^ *([*+-]|\\d+\\.) +/, '')\nconst removeSpaces = replace(/^ */gm, '')\nconst matchBullet = match(/^(\\d)/)\nconst precedeList = replace(/\\n(?=\\d*\\. )/, '\\n\\n')\n\nconst captureList = (source: string, tokenize: Tokenizer): Parsed<NodeList> | null=> {\n  const result = execList(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const bull = result[2]\n\n  const parseChild = compose(tokenize, precedeList, removeSpaces, removeBullets)\n  const topItemsParsed = matchItems(capture).map((item): NodeListItem => {\n    let itemChildren = parseChild(item)\n\n    if (itemChildren.length === 1 && itemChildren[0].type === 'paragraph') {\n      itemChildren = (itemChildren[0] as NodeParagraph).children\n    }\n\n    return {\n      type: 'listitem',\n      children: itemChildren\n    }\n  })\n\n  const startToken = matchBullet(bull)\n  const token: NodeList = {\n    type: 'list',\n    ordered: !!startToken,\n    start: startToken && +startToken[1],\n    children: topItemsParsed\n  }\n\n  return {\n    token,\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureList }\n","import { exec } from 'utils'\n\nimport { NodeText, Parsed } from 'models'\n\nconst execEscape = exec(/^\\\\([\\\\`*{}[\\]()#+\\-.!_>~|])/)\nconst captureEscape = (source: string): Parsed<NodeText> | null => {\n  if (source[0] !== '\\\\') {\n      return null\n  }\n\n  const result = execEscape(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'text',\n      value: capture\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureEscape }\n","import { exec, matches } from 'utils'\n\nimport { Parsed, NodeLink, Tokenizer, NodeImage } from 'models'\n\nconst execAutolink = exec(/^<([^ >]+(@|:\\/)[^ >]+)>/)\nconst captureAutolink = (source: string): Parsed<NodeLink> | null => {\n  if (source[0] !== '<') {\n    return null\n  }\n\n  const result = execAutolink(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const at = result[2]\n  let text = result[1]\n  let href = ''\n\n\n  if (at === '@') {\n    text = text.charAt(6) === ':' ? text.substring(7) : text\n    href = 'mailto:' + text\n  } else {\n    href = text\n  }\n\n  return {\n    token: {\n      type: 'link',\n      href,\n      children: [\n        {\n          type: 'text',\n          value: text\n        }\n      ]\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst testUrlStart = matches(/^http/)\nconst execUrl = exec(/^(https?:\\/\\/[^\\s<]+[^<.,:;\"')\\]\\s])/)\nconst captureUrl = (source: string): Parsed<NodeLink> | null => {\n  if (!testUrlStart(source)) {\n    return null\n  }\n\n  const result = execUrl(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const text = result[1]\n\n  return {\n    token: {\n      type: 'link',\n      href: text,\n      children: [\n        {\n          type: 'text',\n          value: text\n        }\n      ]\n    },\n    newSource: source.substring(capture.length)\n  }\n\n}\n\nconst execLink = exec(/^!?\\[((?:\\[[^\\]]*\\]|[^[\\]]|\\](?=[^[]*\\]))*)\\]\\(\\s*<?([\\s\\S]*?)>?(?:\\s+['\"]([\\s\\S]*?)['\"])?\\s*\\)/)\nconst captureLink = (source: string, inlineLexer: Tokenizer): Parsed<NodeLink | NodeImage> | null => {\n  if (source[0] !== '[' && source[0] !== '!') {\n    return null\n  }\n\n  const result = execLink(source)\n  let token: NodeLink | NodeImage\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const text = result[1]\n  const href = result[2]\n  const title = result[3]\n\n  if (text[0] === '!') {\n    token = {\n      type: 'image',\n      src: href,\n      alt: text,\n      title\n    }\n  } else {\n    token = {\n      type: 'link',\n      href,\n      title,\n      children: inlineLexer(text)\n    }\n  }\n\n  return {\n    token,\n    newSource: source.substring(capture.length)\n  }\n\n}\n\nconst captureLinks = (source: string, inlineLexer: Tokenizer): Parsed<NodeLink | NodeImage> | null =>\n  captureAutolink(source) || captureUrl(source) || captureLink(source, inlineLexer)\n\nexport { captureLinks }\n","import { exec } from 'utils'\n\nimport { NodeStrong, Parsed, Tokenizer } from 'models'\n\nconst execStrong = exec(/^__([\\s\\S]+?)__(?!_)|^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/)\nconst captureStrong = (source: string, inlineLexer: Tokenizer): Parsed<NodeStrong> | null => {\n  if (source[0] !== '_' && source[0] !== '*') {\n      return null\n  }\n\n  const result = execStrong(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const a = result[1]\n  const b = result[2]\n\n  return {\n    token: {\n      type: 'strong',\n      children: inlineLexer(b || a)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureStrong }\n","import { exec } from 'utils'\n\nimport { NodeEm, Parsed, Tokenizer } from 'models'\n\nconst execEm = exec(/^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/)\nconst captureEm = (source: string, inlineLexer: Tokenizer): Parsed<NodeEm> | null => {\n  if (source[0] !== '_' && source[0] !== '*') {\n      return null\n  }\n\n  const result = execEm(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const a = result[1]\n  const b = result[2]\n\n  return {\n    token: {\n      type: 'em',\n      children: inlineLexer(b || a)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureEm }\n","import { exec } from 'utils'\n\nimport { NodeStrikethrough, Parsed, Tokenizer } from 'models'\n\nconst execStrikethrough = exec(/^~~(?=\\S)([\\s\\S]*?\\S)~~/)\nconst captureStrikethrough = (source: string, inlineLexer: Tokenizer): Parsed<NodeStrikethrough> | null => {\n  if (source[0] !== '~') {\n      return null\n  }\n\n  const result = execStrikethrough(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const rawValue = result[1]\n\n  return {\n    token: {\n      type: 'strikethrough',\n      children: inlineLexer(rawValue)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureStrikethrough }\n","import { exec } from 'utils'\n\nimport { NodeCode, Parsed } from 'models'\n\nconst execCode = exec(/^(`+)\\s*([\\s\\S]*?[^`])\\s*\\1(?!`)/)\nconst captureCode = (source: string): Parsed<NodeCode> | null => {\n  if (source[0] !== '`') {\n      return null\n  }\n\n  const result = execCode(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const code = result[2]\n\n  return {\n    token: {\n      type: 'code',\n      value: code\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureCode }\n","import { exec } from 'utils'\n\nimport { NodeLineBreak, Parsed } from 'models'\n\nconst execLineBreak = exec(/^ *\\n(?!\\s*$)/)\nconst captureLineBreak = (source: string): Parsed<NodeLineBreak> | null => {\n  const result = execLineBreak(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'br'\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureLineBreak }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeText } from 'models'\n\nconst execText = exec(/^[\\s\\S]+?(?=[\\\\<![_*`~]|https?:\\/\\/| *\\n|$)/)\n\nconst captureText = (source: string): Parsed<NodeText> | null => {\n  const result = execText(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'text',\n      value: capture\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureText }\n","import { clearSource } from 'utils'\nimport {\n  captureBlockquote,\n  captureCodeBlock,\n  captureHeading,\n  captureHR,\n  captureList,\n  captureNewLine,\n  captureParagraph,\n  captureTable,\n\n  captureCode,\n  captureEm,\n  captureEscape,\n  captureLineBreak,\n  captureLinks,\n  captureStrikethrough,\n  captureStrong,\n  captureText\n} from 'parsers'\n\nimport { NodeItem, Parsed, Parser, Tokenizer } from 'models'\n\ntype ParsersList = { parser: Parser, priority: number }[]\n\nconst MDJ = () => {\n  const parsers: {\n    block: ParsersList\n    inline: ParsersList\n  } = {\n    block: [\n      { parser: captureNewLine, priority: 1000 },\n      { parser: captureHeading, priority: 900 },\n      { parser: captureHR, priority: 800 },\n      { parser: captureBlockquote, priority: 700 },\n      { parser: captureCodeBlock, priority: 600 },\n      { parser: captureTable, priority: 500 },\n      { parser: captureList, priority: 400 },\n      { parser: captureParagraph, priority: 0 }\n    ],\n    inline: [\n      { parser: captureEscape, priority: 1000 },\n      { parser: captureCode, priority: 900 },\n      { parser: captureStrong, priority: 800 },\n      { parser: captureEm, priority: 700 },\n      { parser: captureStrikethrough, priority: 600 },\n      { parser: captureLinks, priority: 500 },\n      { parser: captureLineBreak, priority: 400 },\n      { parser: captureText, priority: 0 }\n    ]\n  }\n\n  const blockLexer: Tokenizer = lexer('block')\n  const inlineLexer: Tokenizer = lexer('inline')\n\n  function addParser (type: 'block' | 'inline', parser: Parser, priority: number) {\n    parsers[type].push({parser, priority})\n    parsers[type] = parsers[type].sort((a, b) => b.priority - a.priority)\n  }\n\n  function pinchToken (type: 'block' | 'inline', source: string): Parsed<NodeItem> | null {\n    const l = parsers[type].length\n    let token\n    let newSource = ''\n\n    for (let i = 0; i < l; i += 1) {\n      const parser = parsers[type][i].parser\n      const parsed = type === 'block' ?\n        parser(source, blockLexer, inlineLexer) :\n        parser(source, inlineLexer)\n\n      if (parsed) {\n        newSource = parsed.newSource\n        token = parsed.token\n        break\n      }\n    }\n\n    if (!token) {\n      return null\n    }\n\n    return {\n      token,\n      newSource\n    }\n  }\n\n  function lexer (type: 'block' | 'inline') {\n    return (source: string): NodeItem[] => {\n      const tokens: NodeItem[] = []\n\n      while (source.length > 0) {\n        const {token = null, newSource = ''} = pinchToken(type, source) || {}\n\n        if (source === newSource || !token) {\n          throw new Error('Infinite loop on byte: ' + source.charCodeAt(0))\n        }\n\n        tokens.push(token)\n        source = newSource\n      }\n\n      return tokens\n    }\n  }\n\n  function prepareSource(source: string) {\n    return clearSource(source)\n  }\n\n  return {\n    parse: function parse(source: string) {\n      return blockLexer(prepareSource(source))\n    },\n    useInlineParser: function useInlineParser(parser: Parser, priority: number) {\n      addParser('inline', parser, priority)\n      return this\n    },\n    useBlockParser: function useBlockParser(parser: Parser, priority: number) {\n      addParser('block', parser, priority)\n      return this\n    }\n  }\n}\n\nexport { MDJ }\n","import { MDJ } from 'core/MDJ'\n\nconst parse = (source: string) => MDJ()\n  .parse(source)\n\nexport default MDJ\nexport { parse }\n"],"names":["curry","fn","arguments","length","inner","args","Array","prototype","slice","call","apply","bind","concat","exec","regExp","input","match","replace","from","to","split","matches","withWhat","what","test","clearSource","compose","a","b","fns","l","arg","result","i","map","execCodeNormal","where","indexOf","clearCode","execCodeFence","captureCodeNormal","source","capture","token","type","language","value","newSource","substring","captureCodeFence","captureCodeBlock","execNewLine","captureNewLine","execHeading","execLHeading","getLevel","captureHeading","_","inlineLexer","level","rawValue","children","execBlockquote","clearBlockquote","captureBlockquote","tokenize","removeHeaderBounds","removeCellBounds","removeRowBounds","removeLastLineBreak","removeLastBounds","splitByLineBreak","isRight","isCenter","getTableHeader","item","trim","getTableRow","getCellAlign","getTableAlign","getNormalCells","lexer","cells","getNPCells","execNPTable","execTableNormal","captureTable","isNP","header","align","execHR","captureHR","execParagraph","captureParagraph","execList","matchItems","removeBullets","removeSpaces","matchBullet","precedeList","captureList","bull","parseChild","topItemsParsed","itemChildren","startToken","ordered","start","execEscape","captureEscape","execAutolink","captureAutolink","at","text","href","charAt","testUrlStart","execUrl","captureUrl","execLink","captureLink","title","src","alt","captureLinks","execStrong","captureStrong","execEm","captureEm","execStrikethrough","captureStrikethrough","execCode","captureCode","execLineBreak","captureLineBreak","execText","captureText","MDJ","parser","priority","parsers","push","sort","parsed","blockLexer","tokens","_a","_b","_c","Error","charCodeAt","block","inline","parse","prepareSource","useInlineParser","addParser","this","useBlockParser"],"mappings":"oMA6CA,IAAMA,GAAe,WACnB,GAAMC,GAAeC,UAAU,GACzBC,EAASF,EAAGE,OAEZC,EAAQ,WACZ,GAAIC,GAAOC,MAAMC,UAAUC,MAAMC,KAAKP,UAEtC,OAAIG,GAAKF,QAAUA,EACVF,EAAGS,MAAM,KAAML,GAEfD,EAAMO,KAAKD,MAAMN,GAAQ,MAAMQ,OAAOP,IAIjD,OAAOD,GAAMO,KAAKD,MAAMN,GAAQ,MAAMQ,OAAON,MAAMC,UAAUC,MAAMC,KAAKP,UAAW,MCzD/EW,EAAOb,EAAM,SAACc,EAAgBC,GAAmC,MAAAD,GAAOD,KAAKE,KCA7EC,EAAQhB,EAAM,SAACc,EAAgBC,GAAkB,MAAAA,GAAMC,MAAMF,SCA7DG,EAAUjB,EAAM,SAACkB,EAAuBC,EAAYJ,GAAkB,MAAAA,GAAME,QAAQC,EAAMC,KCA1FC,EAAQpB,EAAM,SAACc,EAAyBC,GAA4B,MAAAA,GAAMK,MAAMN,KCAhFO,EAAUrB,EAAM,SAACsB,EAAkBC,GAAiB,MAAAD,GAASE,KAAKD,KCFlEE,EAAc,SAACV,GAAkB,MAAAA,GAAME,QAAQ,WAAY,MAC9DA,QAAQ,MAAO,QACfA,QAAQ,UAAW,KACnBA,QAAQ,UAAW,MACnBA,QAAQ,SAAU,KCsBfS,GCxBS1B,EAAM,SAAC2B,EAAQC,GAAoB,MAAAD,KAAMC,IDwB/B,WACvB,GAAMC,GAAMvB,MAAMC,UAAUC,MAAMC,KAAKP,WACjC4B,EAAID,EAAI1B,OAAS,CAEvB,OAAO,UAAS4B,GAGd,IAAK,GAFDC,GAASD,EAEJE,EAAIH,EAAGG,GAAK,EAAGA,GAAK,EAC3BD,EAASH,EAAII,GAAGD,EAGlB,OAAOA,ME9BLE,EAAWlC,EAAM,SAAOC,EAAwCc,GAGpE,IAAK,GAFCiB,GAAS,GAAI1B,OAAMS,EAAMZ,QAEtB8B,EAAI,EAAGA,EAAIlB,EAAMZ,OAAQ8B,GAAK,EACrCD,EAAOC,GAAKhC,EAAGc,EAAMkB,GAAIA,EAAGlB,EAG9B,OAAOiB,KCVHG,GCFanC,EAAM,SAACuB,EAAca,GAAkB,MAAwB,KAAxBA,EAAMC,QAAQd,KDEjDV,EAAK,sBACtByB,EAAYrB,EAAQ,UAAW,IAC/BsB,EAAgB1B,EAAK,8DAErB2B,EAAoB,SAACC,GACzB,GAAkB,MAAdA,EAAO,GACT,MAAO,KAGT,IAAMT,GAASG,EAAeM,EAE9B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEW,OACEC,KAAM,YACNC,SAAU,GACVC,MAAOR,EAAUI,IAEnBK,UAAWN,EAAOO,UAAUN,EAAQvC,UAIlC8C,EAAmB,SAACR,GACxB,GAAMT,GAASO,EAAcE,EAE7B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAIvB,QACEW,OACEC,KAAM,YACNC,SANab,EAAO,GAOpBc,MANUd,EAAO,IAQnBe,UAAWN,EAAOO,UAAUN,EAAQvC,UAIlC+C,EAAmB,SAACT,GACxB,MAAAD,GAAkBC,IAAWQ,EAAiBR,IEjD1CU,EAActC,EAAK,QAEnBuC,EAAiB,SAACX,GACtB,GAAMT,GAASmB,EAAYV,EAE3B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEW,OAASC,KAAM,SACfG,UAAWN,EAAOO,UAAUN,EAAQvC,UCblCkD,EAAcxC,EAAK,yCACnByC,EAAezC,EAAK,sCACpB0C,EAAW,SAACxC,GAChB,MAAiB,MAAbA,EAAM,GACDA,EAAMZ,OAGE,MAAVY,EAAgB,EAAI,GAGvByC,EAAiB,SAACf,EAAgBgB,EAAQC,GAC9C,GAAM1B,GAAwB,MAAdS,EAAO,IAAcY,EAAYZ,IAAYa,EAAab,EAE1E,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjB2B,EAAQ3B,EAAO,GACf4B,EAAW5B,EAAO,EAExB,QACEW,OACEC,KAAM,UACNe,MAAOJ,EAASI,GAChBE,SAAUH,EAAYE,IAExBb,UAAWN,EAAOO,UAAUN,EAAQvC,UC3BlC2D,EAAiBjD,EAAK,mGACtBkD,EAAkB9C,EAAQ,WAAY,IACtC+C,EAAoB,SAACvB,EAAgBwB,GACzC,GAAkB,MAAdxB,EAAO,GACT,MAAO,KAGT,IAAMT,GAAS8B,EAAerB,EAE9B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GAEnB6B,EAAWI,EAASF,EAAgBrB,GAMxC,OAJwB,KAApBmB,EAAS1D,QAAqC,cAArB0D,EAAS,GAAGjB,OACvCiB,EAAYA,EAAS,GAAqBA,WAI1ClB,OACEC,KAAM,aACNiB,SAAUI,EAASF,EAAgBrB,KAErCK,UAAWN,EAAOO,UAAUN,EAAQvC,UCzBlC+D,EAAqBjD,EAAQ,eAAgB,IAC7CkD,EAAmBlD,EAAQ,mBAAoB,IAC/CmD,EAAkBnD,EAAQ,aAAc,IACxCoD,EAAsBpD,EAAQ,MAAO,KACrCqD,EAAmBrD,EAAQ,iBAAkB,IAC7CsD,EAAmBnD,EAAM,MACzBoD,EAAUnD,EAAQ,aAClBoD,EAAWpD,EAAQ,cAEnBqD,EAAiB,SAACjC,GAA6B,MAAAyB,GAAmBzB,GAAQrB,MAVjE,UAU+Ec,IAAI,SAAAyC,GAAQ,MAAAA,GAAKC,UACzGC,EAAcnD,EAAQN,EAXb,UAW4B+C,GACrCW,EAAe,SAAC/D,GACpB,MAAIyD,GAAQzD,GACH,QACE0D,EAAS1D,GACX,SAEA,QAGLgE,EAAgB,SAACtC,GAAyC,MAAA2B,GAAgB3B,GAAQrB,MArBzE,UAqBuFc,IAAI4C,IACpGE,EAAiB,SAACC,EAAkBC,GACxC,MAAAxD,GAAQQ,EAAIR,EAAQQ,EAAI+C,GAAQJ,IAAeN,EAAkBD,GAAkBY,IAC/EC,EAAa,SAACF,EAAkBC,GACpC,MAAAxD,GAAQQ,EAAIR,EAAQQ,EAAI+C,GAAQ7D,EAzBnB,YAyBoCmD,EAAkBF,GAAqBa,IAEpFE,EAAcvE,EAAK,iEACnBwE,EAAkBxE,EAAK,6DAEvByE,EAAe,SAAC7C,EAAgBgB,EAAQC,GAC5C,GAAI1B,GAASoD,EAAY3C,GACrB8C,GAAO,CAOX,IALKvD,IACHA,EAASqD,EAAgB5C,GACzB8C,GAAO,IAGJvD,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBwD,EAASxD,EAAO,GAChByD,EAAQzD,EAAO,GACfkD,EAAQlD,EAAO,EAErB,OAAKU,IAKHC,OACEC,KAAM,QACN4C,OAAQd,EAAec,GACvBC,MAAOV,EAAcU,GACrBP,MAAOK,EAAOJ,EAAWzB,EAAawB,GAASF,EAAetB,EAAawB,IAE7EnC,UAAWN,EAAOO,UAAUN,EAAQvC,SAV7B,MCjDLuF,EAAS7E,EAAK,wCAEd8E,EAAY,SAAClD,GACjB,GAAMT,GAAS0D,EAAOjD,EAEtB,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEW,OAASC,KAAM,MACfG,UAAWN,EAAOO,UAAUN,EAAQvC,UCblCyF,EAAgB/E,EAAK,wBACrBwD,EAAsBpD,EAAQ,MAAO,KAErC4E,EAAmB,SAACpD,EAAgBgB,EAAQC,GAChD,GAAM1B,GAAS4D,EAAcnD,EAE7B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjB4B,EAAW5B,EAAO,EAExB,QACEW,OACEC,KAAM,YACNiB,SAAUH,EAAYW,EAAoBT,KAE5Cb,UAAWN,EAAOO,UAAUN,EAAQvC,UCjBlC2F,EAAWjF,EAAK,2LAChBkF,EAAa/E,EAAM,sEACnBgF,EAAgB/E,EAAQ,qBAAsB,IAC9CgF,EAAehF,EAAQ,QAAS,IAChCiF,EAAclF,EAAM,SACpBmF,EAAclF,EAAQ,eAAgB,QAEtCmF,EAAc,SAAC3D,EAAgBwB,GACnC,GAAMjC,GAAS8D,EAASrD,EAExB,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBqE,EAAOrE,EAAO,GAEdsE,EAAa5E,EAAQuC,EAAUkC,EAAaF,EAAcD,GAC1DO,EAAiBR,EAAWrD,GAASR,IAAI,SAACyC,GAC9C,GAAI6B,GAAeF,EAAW3B,EAM9B,OAJ4B,KAAxB6B,EAAarG,QAAyC,cAAzBqG,EAAa,GAAG5D,OAC/C4D,EAAgBA,EAAa,GAAqB3C,WAIlDjB,KAAM,WACNiB,SAAU2C,KAIRC,EAAaP,EAAYG,EAQ/B,QACE1D,OAPAC,KAAM,OACN8D,UAAWD,EACXE,MAAOF,IAAeA,EAAW,GACjC5C,SAAU0C,GAKVxD,UAAWN,EAAOO,UAAUN,EAAQvC,UC1ClCyG,GAAa/F,EAAK,gCAClBgG,GAAgB,SAACpE,GACrB,GAAkB,OAAdA,EAAO,GACP,MAAO,KAGX,IAAMT,GAAS4E,GAAWnE,EAE1B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEW,OACEC,KAAM,OACNE,MAAOJ,GAETK,UAAWN,EAAOO,UAAUN,EAAQvC,UCnBlC2G,GAAejG,EAAK,4BACpBkG,GAAkB,SAACtE,GACvB,GAAkB,MAAdA,EAAO,GACT,MAAO,KAGT,IAAMT,GAAS8E,GAAarE,EAE5B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBgF,EAAKhF,EAAO,GACdiF,EAAOjF,EAAO,GACdkF,EAAO,EAUX,OAPW,MAAPF,GACFC,EAA0B,MAAnBA,EAAKE,OAAO,GAAaF,EAAKjE,UAAU,GAAKiE,EACpDC,EAAO,UAAYD,GAEnBC,EAAOD,GAIPtE,OACEC,KAAM,OACNsE,OACArD,WAEIjB,KAAM,OACNE,MAAOmE,KAIblE,UAAWN,EAAOO,UAAUN,EAAQvC,UAIlCiH,GAAe/F,EAAQ,SACvBgG,GAAUxG,EAAK,wCACfyG,GAAa,SAAC7E,GAClB,IAAK2E,GAAa3E,GAChB,MAAO,KAGT,IAAMT,GAASqF,GAAQ5E,EAEvB,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBiF,EAAOjF,EAAO,EAEpB,QACEW,OACEC,KAAM,OACNsE,KAAMD,EACNpD,WAEIjB,KAAM,OACNE,MAAOmE,KAIblE,UAAWN,EAAOO,UAAUN,EAAQvC,UAKlCoH,GAAW1G,EAAK,mGAChB2G,GAAc,SAAC/E,EAAgBiB,GACnC,GAAkB,MAAdjB,EAAO,IAA4B,MAAdA,EAAO,GAC9B,MAAO,KAGT,IACIE,GADEX,EAASuF,GAAS9E,EAGxB,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBiF,EAAOjF,EAAO,GACdkF,EAAOlF,EAAO,GACdyF,EAAQzF,EAAO,EAkBrB,OAfEW,GADc,MAAZsE,EAAK,IAELrE,KAAM,QACN8E,IAAKR,EACLS,IAAKV,EACLQ,UAIA7E,KAAM,OACNsE,OACAO,QACA5D,SAAUH,EAAYuD,KAKxBtE,QACAI,UAAWN,EAAOO,UAAUN,EAAQvC,UAKlCyH,GAAe,SAACnF,EAAgBiB,GACpC,MAAAqD,IAAgBtE,IAAW6E,GAAW7E,IAAW+E,GAAY/E,EAAQiB,IClHjEmE,GAAahH,EAAK,kDAClBiH,GAAgB,SAACrF,EAAgBiB,GACrC,GAAkB,MAAdjB,EAAO,IAA4B,MAAdA,EAAO,GAC5B,MAAO,KAGX,IAAMT,GAAS6F,GAAWpF,EAE1B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBL,EAAIK,EAAO,EAGjB,QACEW,OACEC,KAAM,SACNiB,SAAUH,EALJ1B,EAAO,IAKcL,IAE7BoB,UAAWN,EAAOO,UAAUN,EAAQvC,UCrBlC4H,GAASlH,EAAK,yDACdmH,GAAY,SAACvF,EAAgBiB,GACjC,GAAkB,MAAdjB,EAAO,IAA4B,MAAdA,EAAO,GAC5B,MAAO,KAGX,IAAMT,GAAS+F,GAAOtF,EAEtB,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBL,EAAIK,EAAO,EAGjB,QACEW,OACEC,KAAM,KACNiB,SAAUH,EALJ1B,EAAO,IAKcL,IAE7BoB,UAAWN,EAAOO,UAAUN,EAAQvC,UCrBlC8H,GAAoBpH,EAAK,2BACzBqH,GAAuB,SAACzF,EAAgBiB,GAC5C,GAAkB,MAAdjB,EAAO,GACP,MAAO,KAGX,IAAMT,GAASiG,GAAkBxF,EAEjC,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAGvB,QACEW,OACEC,KAAM,gBACNiB,SAAUH,EALG1B,EAAO,KAOtBe,UAAWN,EAAOO,UAAUN,EAAQvC,UCpBlCgI,GAAWtH,EAAK,oCAChBuH,GAAc,SAAC3F,GACnB,GAAkB,MAAdA,EAAO,GACP,MAAO,KAGX,IAAMT,GAASmG,GAAS1F,EAExB,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAGvB,QACEW,OACEC,KAAM,OACNE,MALSd,EAAO,IAOlBe,UAAWN,EAAOO,UAAUN,EAAQvC,UCpBlCkI,GAAgBxH,EAAK,iBACrByH,GAAmB,SAAC7F,GACxB,GAAMT,GAASqG,GAAc5F,EAE7B,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEW,OACEC,KAAM,MAERG,UAAWN,EAAOO,UAAUN,EAAQvC,UCdlCoI,GAAW1H,EAAK,+CAEhB2H,GAAc,SAAC/F,GACnB,GAAMT,GAASuG,GAAS9F,EAExB,KAAKT,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEW,OACEC,KAAM,OACNE,MAAOJ,GAETK,UAAWN,EAAOO,UAAUN,EAAQvC,UCKlCsI,GAAM,WA8BV,WAAoB7F,EAA0B8F,EAAgBC,GAC5DC,EAAQhG,GAAMiG,MAAMH,SAAQC,aAC5BC,EAAQhG,GAAQgG,EAAQhG,GAAMkG,KAAK,SAACnH,EAAGC,GAAM,MAAAA,GAAE+G,SAAWhH,EAAEgH,WAG9D,WAAqB/F,EAA0BH,GAK7C,IAAK,GAHDE,GADEb,EAAI8G,EAAQhG,GAAMzC,OAEpB4C,EAAY,GAEPd,EAAI,EAAGA,EAAIH,EAAGG,GAAK,EAAG,CAC7B,GAAMyG,GAASE,EAAQhG,GAAMX,GAAGyG,OAC1BK,EAAkB,UAATnG,EACb8F,EAAOjG,EAAQuG,EAAYtF,GAC3BgF,EAAOjG,EAAQiB,EAEjB,IAAIqF,EAAQ,CACVhG,EAAYgG,EAAOhG,UACnBJ,EAAQoG,EAAOpG,KACf,QAIJ,MAAKA,IAKHA,QACAI,aALO,KASX,WAAgBH,GACd,MAAO,UAACH,GAGN,IAFA,GAAMwG,MAECxG,EAAOtC,OAAS,GAAG,CAClB,GAAA+I,cAACC,UAAAxG,oBAAcyG,cAAArG,iBAErB,IAAIN,IAAWM,IAAcJ,EAC3B,KAAM,IAAI0G,OAAM,0BAA4B5G,EAAO6G,WAAW,GAGhEL,GAAOJ,KAAKlG,GACZF,EAASM,EAGX,MAAOkG,IAIX,WAAuBxG,GACrB,MAAOhB,GAAYgB,GAlFrB,GAAMmG,IAIJW,QACIb,OAAQtF,EAAgBuF,SAAU,MAClCD,OAAQlF,EAAgBmF,SAAU,MAClCD,OAAQ/C,EAAWgD,SAAU,MAC7BD,OAAQ1E,EAAmB2E,SAAU,MACrCD,OAAQxF,EAAkByF,SAAU,MACpCD,OAAQpD,EAAcqD,SAAU,MAChCD,OAAQtC,EAAauC,SAAU,MAC/BD,OAAQ7C,EAAkB8C,SAAU,IAExCa,SACId,OAAQ7B,GAAe8B,SAAU,MACjCD,OAAQN,GAAaO,SAAU,MAC/BD,OAAQZ,GAAea,SAAU,MACjCD,OAAQV,GAAWW,SAAU,MAC7BD,OAAQR,GAAsBS,SAAU,MACxCD,OAAQd,GAAce,SAAU,MAChCD,OAAQJ,GAAkBK,SAAU,MACpCD,OAAQF,GAAaG,SAAU,KAI/BK,EAAwB/D,EAAM,SAC9BvB,EAAyBuB,EAAM,SA0DrC,QACEwE,MAAO,SAAehH,GACpB,MAAOuG,GAAWU,EAAcjH,KAElCkH,gBAAiB,SAAyBjB,EAAgBC,GAExD,MADAiB,GAAU,SAAUlB,EAAQC,GACrBkB,MAETC,eAAgB,SAAwBpB,EAAgBC,GAEtD,MADAiB,GAAU,QAASlB,EAAQC,GACpBkB,QCvHPJ,GAAQ,SAAChH,GAAmB,MAAAgG,MAC/BgB,MAAMhH"}
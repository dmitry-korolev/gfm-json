{"version":3,"file":"index.js","sources":["src/utils/curry.ts","src/utils/exec.ts","src/utils/match.ts","src/utils/replace.ts","src/utils/split.ts","src/utils/matches.ts","src/utils/clearSource.ts","src/utils/compose.ts","src/utils/equals.ts","src/utils/map.ts","src/blockParsers/captureBlockquote.ts","src/utils/startsWith.ts","src/blockParsers/captureCodeBlock.ts","src/blockParsers/captureHeading.ts","src/blockParsers/captureHR.ts","src/blockParsers/captureHTML.ts","src/blockParsers/captureList.ts","src/blockParsers/captureNewLine.ts","src/blockParsers/captureParagraph.ts","src/blockParsers/captureTable.ts","src/inlineParsers/captureCode.ts","src/inlineParsers/captureEm.ts","src/inlineParsers/captureEscape.ts","src/inlineParsers/captureLinebreak.ts","src/inlineParsers/captureLinks.ts","src/inlineParsers/captureStrikethrough.ts","src/inlineParsers/captureStrong.ts","src/inlineParsers/captureText.ts","src/core/MDJ.ts","src/index.ts"],"sourcesContent":["// Yep, interfaces are stolen from ramda types\ninterface CurriedFunction2<T1, T2, R> {\n  (t1: T1): (t2: T2) => R\n  (t1: T1, t2: T2): R\n}\n\ninterface CurriedFunction3<T1, T2, T3, R> {\n  (t1: T1): CurriedFunction2<T2, T3, R>\n  (t1: T1, t2: T2): (t3: T3) => R\n  (t1: T1, t2: T2, t3: T3): R\n}\n\ninterface CurriedFunction4<T1, T2, T3, T4, R> {\n  (t1: T1): CurriedFunction3<T2, T3, T4, R>\n  (t1: T1, t2: T2): CurriedFunction2<T3, T4, R>\n  (t1: T1, t2: T2, t3: T3): (t4: T4) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4): R\n}\n\ninterface CurriedFunction5<T1, T2, T3, T4, T5, R> {\n  (t1: T1): CurriedFunction4<T2, T3, T4, T5, R>\n  (t1: T1, t2: T2): CurriedFunction3<T3, T4, T5, R>\n  (t1: T1, t2: T2, t3: T3): CurriedFunction2<T4, T5, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4): (t5: T5) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5): R\n}\n\ninterface CurriedFunction6<T1, T2, T3, T4, T5, T6, R> {\n  (t1: T1): CurriedFunction5<T2, T3, T4, T5, T6, R>\n  (t1: T1, t2: T2): CurriedFunction4<T3, T4, T5, T6, R>\n  (t1: T1, t2: T2, t3: T3): CurriedFunction3<T4, T5, T6, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4): CurriedFunction2<T5, T6, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5): (t6: T6) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5, t6: T6): R\n}\n\ninterface Curry {\n  <T1, T2, TResult>(fn: (a: T1, b: T2) => TResult, args?: any): CurriedFunction2<T1,T2, TResult>\n  <T1, T2, T3, TResult>(fn: (a: T1, b: T2, c: T3) => TResult, args?: any): CurriedFunction3<T1,T2, T3, TResult>\n  <T1, T2, T3, T4, TResult>(fn: (a: T1, b: T2, c: T3, d: T4) => TResult, args?: any): CurriedFunction4<T1,T2, T3, T4, TResult>\n  <T1, T2, T3, T4, T5, TResult>(fn: (a: T1, b: T2, c: T3, d: T4, e: T5) => TResult, args?: any): CurriedFunction5<T1,T2, T3, T4, T5, TResult>\n  <T1, T2, T3, T4, T5, T6, TResult>(fn: (a: T1, b: T2, c: T3, d: T4, e: T5, f: T6) => TResult, args?: any): CurriedFunction6<T1,T2, T3, T4, T5, T6, TResult>\n  (fn: Function): Function\n}\n\nconst curry: Curry = function() {\n  const fn: Function = arguments[0]\n  const length = fn.length\n\n  const inner = function() {\n    let args = Array.prototype.slice.call(arguments)\n\n    if (args.length >= length) {\n      return fn.apply(null, args)\n    } else {\n      return inner.bind.apply(inner, [null].concat(args))\n    }\n  }\n\n  return inner.bind.apply(inner, [null].concat(Array.prototype.slice.call(arguments, 1)))\n}\n\nexport { curry }\n","import { curry } from 'utils'\n\nconst exec = curry((regExp: RegExp, input: string): string[] | null => regExp.exec(input))\n\nexport { exec }\n\n","import { curry } from 'utils'\n\nconst match = curry((regExp: RegExp, input: string) => input.match(regExp) || [])\n\nexport { match }\n","import { curry } from 'utils'\n\nconst replace = curry((from: string | RegExp, to: string, input: string) => input.replace(from, to))\n\nexport { replace }\n","import { curry } from 'utils'\n\nconst split = curry((regExp: RegExp | string, input: string): string[] => input.split(regExp))\n\nexport { split }\n","import { curry } from 'utils'\n\nconst matches = curry((withWhat: RegExp, what: string) => withWhat.test(what))\n\nexport { matches }\n","const clearSource = (input: string) => input.replace(/\\r\\n|\\r/g, '\\n')\n  .replace(/\\t/g, '    ')\n  .replace(/\\u00a0/g, ' ')\n  .replace(/\\u2424/g, '\\n')\n  .replace(/^ +$/gm, '')\n\nexport { clearSource }\n","interface Compose {\n  <V0, T1>(fn0: (x0: V0) => T1): (x0: V0) => T1;\n  <V0, V1, T1>(fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T1;\n  <V0, V1, V2, T1>(fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T1;\n\n  <V0, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0) => T1): (x0: V0) => T2;\n  <V0, V1, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T2;\n  <V0, V1, V2, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T2;\n\n  <V0, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T3;\n  <V0, V1, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T3;\n  <V0, V1, V2, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T3;\n\n  <V0, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T4;\n  <V0, V1, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T4;\n  <V0, V1, V2, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T4;\n\n  <V0, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T5;\n  <V0, V1, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T5;\n  <V0, V1, V2, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T5;\n\n  <V0, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T6;\n  <V0, V1, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T6;\n  <V0, V1, V2, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T6;\n}\n\nconst compose: Compose = function () {\n  const fns = Array.prototype.slice.call(arguments)\n  const l = fns.length - 1\n\n  return function(arg: any) {\n    let result = arg\n\n    for (let i = l; i >= 0; i -= 1) {\n      result = fns[i](result)\n    }\n\n    return result\n  }\n}\n\nexport { compose }\n","import { curry } from 'utils'\n\nconst equals = curry((a: any, b: any): boolean => a === b)\n\nexport { equals }\n","import { curry } from 'utils'\n\ninterface Map {\n  <V, R>(fn: (x0: V, x1: number, x2: V[]) => R): (input: V[]) => R[]\n  <V, R>(fn: (x0: V, x1: number, x2: V[]) => R, input: V[]): R[]\n}\n\nconst map: Map = curry(<V, R>(fn: (x0: V, x1: number, x2: V[]) => R , input: V[]) => {\n  const result = new Array(input.length)\n\n  for (let i = 0; i < input.length; i += 1) {\n    result[i] = fn(input[i], i, input)\n  }\n\n  return result\n})\n\nexport { map }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeBlockquote, Tokenizer, NodeParagraph } from 'models'\n\nconst execBlockquote = exec(/^( *>[^\\n]+(\\n(?! *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +[\"(]([^\\n]+)[\")])? *(?:\\n+|$))[^\\n]+)*\\n*)+/)\nconst clearBlockquote = replace(/^ *> ?/gm, '')\nconst captureBlockquote = (source: string, tokenize: Tokenizer): Parsed<NodeBlockquote> | null => {\n  if (source[0] !== '>') {\n    return null\n  }\n\n  const result = execBlockquote(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  let children = tokenize(clearBlockquote(capture))\n\n  if (children.length === 1 && children[0].type === 'paragraph') {\n    children = (children[0] as NodeParagraph).children\n  }\n\n  return {\n    token: {\n      type: 'blockquote',\n      children: tokenize(clearBlockquote(capture))\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureBlockquote }\n","import { curry } from 'utils'\n\nconst startsWith = curry((what: string, where: string) => where.indexOf(what) === 0)\n\nexport { startsWith }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeCodeBlock } from 'models'\n\nconst execCodeNormal = exec(/^( {4}[^\\n]+\\n*)+/)\nconst clearCode = replace(/^ {4}/gm, '')\nconst execCodeFence = exec(/^ *(`{3,}|~{3,})[ \\.]*(\\S+)? *\\n([\\s\\S]*?)\\s*\\1 *(?:\\n+|$)/)\n\nconst captureCodeNormal = (source: string): Parsed<NodeCodeBlock> | null => {\n  if (source[0] !== '`') {\n    return null\n  }\n\n  const result = execCodeNormal(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'codeblock',\n      language: '',\n      value: clearCode(capture)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst captureCodeFence = (source: string): Parsed<NodeCodeBlock> | null => {\n  const result = execCodeFence(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const language = result[2]\n  const value = result[3]\n\n  return {\n    token: {\n      type: 'codeblock',\n      language,\n      value\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst captureCodeBlock = (source: string): Parsed<NodeCodeBlock> | null =>\n  captureCodeNormal(source) || captureCodeFence(source)\nexport { captureCodeBlock }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeHeading, Tokenizer } from 'models'\n\nconst execHeading = exec(/^ *(#{1,6}) +([^\\n]+?) *#* *(?:\\n+|$)/)\nconst execLHeading = exec(/^([^\\n]+)\\n *([=-]){2,} *(?:\\n+|$)/)\nconst getLevel = (input: string): number => {\n  if (input[0] === '#') {\n    return input.length\n  }\n\n  return input === '=' ? 1 : 2\n}\n\nconst captureHeading = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeHeading> | null => {\n  const result = (source[0] === '#' && execHeading(source)) || execLHeading(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const level = result[1]\n  const rawValue = result[2]\n\n  return {\n    token: {\n      type: 'heading',\n      level: getLevel(level),\n      children: inlineLexer(rawValue)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\n\nexport { captureHeading }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeHR } from 'models'\n\nconst execHR = exec(/^ *(?:\\*{3,}|-{3,}|_{3,}) *(?:\\n+|$)/)\n\nconst captureHR = (source: string): Parsed<NodeHR> | null => {\n  const result = execHR(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: { type: 'hr' },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureHR }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeHTML } from 'models'\n\nconst execHTML = exec(/^(?:<!--[\\s\\S]*?--> *(?:\\n|\\s*$)|<((?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\b)\\w+(?!:\\/|[^\\w\\s@]*@)\\b)[\\s\\S]+?<\\/\\1> *(?:\\n{2,}|\\s*$)|<(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\b)\\w+(?!:\\/|[^\\w\\s@]*@)\\b(?:\"[^\"]*\"|'[^']*'|[^'\">])*?> *(?:\\n{2,}|\\s*$))/)\n\nconst captureHTML = (source: string): Parsed<NodeHTML> | null => {\n  if (source[0] !== '<') {\n    return null\n  }\n\n  const result = execHTML(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'html',\n      value: capture\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureHTML }\n","import { exec, match, replace, compose } from 'utils'\n\nimport { Parsed, NodeList, NodeListItem, Tokenizer, NodeParagraph } from 'models'\nimport {  } from '../utils/match'\n\nconst execList = exec(/^( *)((?:[*+-]|\\d+\\.)) [\\s\\S]+?(?:\\n+(?=\\1?(?:[-*_] *){3,}(?:\\n+|$))|\\n+(?= *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +[\"(]([^\\n]+)[\")])? *(?:\\n+|$))|\\n{2,}(?! )(?!\\1(?:[*+-]|\\d+\\.) )\\n*|\\s*$)/)\nconst matchItems = match(/^( *)((?:[*+-]|\\d+\\.)) [^\\n]*(?:\\n(?!\\1(?:[*+-]|\\d+\\.) )[^\\n]*)*/gm)\nconst removeBullets = replace(/^ *([*+-]|\\d+\\.) +/, '')\nconst removeSpaces = replace(/^ */gm, '')\nconst matchBullet = match(/^(\\d)/)\nconst precedeList = replace(/\\n(?=\\d*\\. )/, '\\n\\n')\n\nconst captureList = (source: string, tokenize: Tokenizer): Parsed<NodeList> | null=> {\n  const result = execList(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const bull = result[2]\n\n  const parseChild = compose(tokenize, precedeList, removeSpaces, removeBullets)\n  const topItemsParsed = matchItems(capture).map((item): NodeListItem => {\n    let itemChildren = parseChild(item)\n\n    if (itemChildren.length === 1 && itemChildren[0].type === 'paragraph') {\n      itemChildren = (itemChildren[0] as NodeParagraph).children\n    }\n\n    return {\n      type: 'listitem',\n      children: itemChildren\n    }\n  })\n\n  const startToken = matchBullet(bull)\n  const token: NodeList = {\n    type: 'list',\n    ordered: !!startToken,\n    start: startToken && +startToken[1],\n    children: topItemsParsed\n  }\n\n  return {\n    token,\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureList }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeSpace } from 'models'\n\nconst execNewLine = exec(/^\\n+/)\n\nconst captureNewLine = (source: string): Parsed<NodeSpace> | null => {\n  const result = execNewLine(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: { type: 'space' },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureNewLine }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeParagraph, Tokenizer } from 'models'\n\nconst execParagraph = exec(/^((?:[^\\n]+\\n?)+)\\n*/)\nconst removeLastLineBreak = replace(/\\n$/, ' ')\n\nconst captureParagraph = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeParagraph> | null => {\n  const result = execParagraph(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const rawValue = result[1]\n\n  return {\n    token: {\n      type: 'paragraph',\n      children: inlineLexer(removeLastLineBreak(rawValue))\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureParagraph }\n","import { exec, matches, replace, compose, map, split } from 'utils'\n\nimport { Parsed, NodeTable, Tokenizer, NodeItem } from 'models'\n\nconst rowSep = / *\\| */\nconst removeHeaderBounds = replace(/^ *| *\\| *$/g, '')\nconst removeCellBounds = replace(/^ *\\| *| *\\| *$/g, '')\nconst removeRowBounds = replace(/^ *|\\| *$/g, '')\nconst removeLastLineBreak = replace(/\\n$/, ' ')\nconst removeLastBounds = replace(/(?: *\\| *)?\\n$/, '')\nconst splitByLineBreak = split('\\n')\nconst isRight = matches(/^ *-+: *$/)\nconst isCenter = matches(/^ *:-+: *$/)\n\nconst getTableHeader = (source: string): string[] => removeHeaderBounds(source).split(rowSep).map(item => item.trim())\nconst getTableRow = compose(split(rowSep), removeCellBounds)\nconst getCellAlign = (input: string): string | null => {\n  if (isRight(input)) {\n    return 'right'\n  } else if (isCenter(input)) {\n    return 'center'\n  } else {\n    return 'left'\n  }\n}\nconst getTableAlign = (source: string): Array<string | null> => removeRowBounds(source).split(rowSep).map(getCellAlign)\nconst getNormalCells = (lexer: Tokenizer, cells: string): NodeItem[][][] =>\n  compose(map(compose(map(lexer), getTableRow)), splitByLineBreak, removeLastBounds)(cells)\nconst getNPCells = (lexer: Tokenizer, cells: string): NodeItem[][][] =>\n  compose(map(compose(map(lexer), split(rowSep))), splitByLineBreak, removeLastLineBreak)(cells)\n\nconst execNPTable = exec(/^ *(\\S.*\\|.*)\\n *([-:]+ *\\|[-| :]*)\\n((?:.*\\|.*(?:\\n|$))*)\\n*/)\nconst execTableNormal = exec(/^ *\\|(.+)\\n *\\|( *[-:]+[-| :]*)\\n((?: *\\|.*(?:\\n|$))*)\\n*/)\n\nconst captureTable = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeTable> | null => {\n  let result = execNPTable(source)\n  let isNP = true\n\n  if (!result) {\n    result = execTableNormal(source)\n    isNP = false\n  }\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const header = result[1]\n  const align = result[2]\n  const cells = result[3]\n\n  if (!capture) {\n    return null\n  }\n\n  return {\n    token: {\n      type: 'table',\n      header: getTableHeader(header),\n      align: getTableAlign(align),\n      cells: isNP ? getNPCells(inlineLexer, cells) : getNormalCells(inlineLexer, cells)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureTable }\n","import { exec } from 'utils'\n\nimport { NodeCode, Parsed } from 'models'\n\nconst execCode = exec(/^(`+)\\s*([\\s\\S]*?[^`])\\s*\\1(?!`)/)\nconst captureCode = (source: string): Parsed<NodeCode> | null => {\n  if (source[0] !== '`') {\n      return null\n  }\n\n  const result = execCode(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const code = result[2]\n\n  return {\n    token: {\n      type: 'code',\n      value: code\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureCode }\n","import { exec } from 'utils'\n\nimport { NodeEm, Parsed, Tokenizer } from 'models'\n\nconst execEm = exec(/^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/)\nconst captureEm = (source: string, inlineLexer: Tokenizer): Parsed<NodeEm> | null => {\n  if (source[0] !== '_' && source[0] !== '*') {\n      return null\n  }\n\n  const result = execEm(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const a = result[1]\n  const b = result[2]\n\n  return {\n    token: {\n      type: 'em',\n      children: inlineLexer(b || a)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureEm }\n","import { exec } from 'utils'\n\nimport { NodeText, Parsed } from 'models'\n\nconst execEscape = exec(/^\\\\([\\\\`*{}[\\]()#+\\-.!_>~|])/)\nconst captureEscape = (source: string): Parsed<NodeText> | null => {\n  if (source[0] !== '\\\\') {\n      return null\n  }\n\n  const result = execEscape(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'text',\n      value: capture\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureEscape }\n","import { exec } from 'utils'\n\nimport { NodeLineBreak, Parsed } from 'models'\n\nconst execLineBreak = exec(/^ *\\n(?!\\s*$)/)\nconst captureLineBreak = (source: string): Parsed<NodeLineBreak> | null => {\n  const result = execLineBreak(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'br'\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureLineBreak }\n","import { exec, matches } from 'utils'\n\nimport { Parsed, NodeLink, Tokenizer, NodeImage } from 'models'\n\nconst execAutolink = exec(/^<([^ >]+(@|:\\/)[^ >]+)>/)\nconst captureAutolink = (source: string): Parsed<NodeLink> | null => {\n  if (source[0] !== '<') {\n    return null\n  }\n\n  const result = execAutolink(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const at = result[2]\n  let text = result[1]\n  let href = ''\n\n\n  if (at === '@') {\n    text = text.charAt(6) === ':' ? text.substring(7) : text\n    href = 'mailto:' + text\n  } else {\n    href = text\n  }\n\n  return {\n    token: {\n      type: 'link',\n      href,\n      children: [\n        {\n          type: 'text',\n          value: text\n        }\n      ]\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst testUrlStart = matches(/^http/)\nconst execUrl = exec(/^(https?:\\/\\/[^\\s<]+[^<.,:;\"')\\]\\s])/)\nconst captureUrl = (source: string): Parsed<NodeLink> | null => {\n  if (!testUrlStart(source)) {\n    return null\n  }\n\n  const result = execUrl(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const text = result[1]\n\n  return {\n    token: {\n      type: 'link',\n      href: text,\n      children: [\n        {\n          type: 'text',\n          value: text\n        }\n      ]\n    },\n    newSource: source.substring(capture.length)\n  }\n\n}\n\nconst execLink = exec(/^!?\\[((?:\\[[^\\]]*\\]|[^[\\]]|\\](?=[^[]*\\]))*)\\]\\(\\s*<?([\\s\\S]*?)>?(?:\\s+['\"]([\\s\\S]*?)['\"])?\\s*\\)/)\nconst captureLink = (source: string, inlineLexer: Tokenizer): Parsed<NodeLink | NodeImage> | null => {\n  if (source[0] !== '[' && source[0] !== '!') {\n    return null\n  }\n\n  const result = execLink(source)\n  let token: NodeLink | NodeImage\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const text = result[1]\n  const href = result[2]\n  const title = result[3]\n\n  if (text[0] === '!') {\n    token = {\n      type: 'image',\n      src: href,\n      alt: text,\n      title\n    }\n  } else {\n    token = {\n      type: 'link',\n      href,\n      title,\n      children: inlineLexer(text)\n    }\n  }\n\n  return {\n    token,\n    newSource: source.substring(capture.length)\n  }\n\n}\n\nconst captureLinks = (source: string, inlineLexer: Tokenizer): Parsed<NodeLink | NodeImage> | null =>\n  captureAutolink(source) || captureUrl(source) || captureLink(source, inlineLexer)\n\nexport { captureLinks }\n","import { exec } from 'utils'\n\nimport { NodeStrikethrough, Parsed, Tokenizer } from 'models'\n\nconst execStrikethrough = exec(/^~~(?=\\S)([\\s\\S]*?\\S)~~/)\nconst captureStrikethrough = (source: string, inlineLexer: Tokenizer): Parsed<NodeStrikethrough> | null => {\n  if (source[0] !== '~') {\n      return null\n  }\n\n  const result = execStrikethrough(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const rawValue = result[1]\n\n  return {\n    token: {\n      type: 'strikethrough',\n      children: inlineLexer(rawValue)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureStrikethrough }\n","import { exec } from 'utils'\n\nimport { NodeStrong, Parsed, Tokenizer } from 'models'\n\nconst execStrong = exec(/^__([\\s\\S]+?)__(?!_)|^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/)\nconst captureStrong = (source: string, inlineLexer: Tokenizer): Parsed<NodeStrong> | null => {\n  if (source[0] !== '_' && source[0] !== '*') {\n      return null\n  }\n\n  const result = execStrong(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const a = result[1]\n  const b = result[2]\n\n  return {\n    token: {\n      type: 'strong',\n      children: inlineLexer(b || a)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureStrong }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeText } from 'models'\n\nconst execText = exec(/^[\\s\\S]+?(?=[\\\\<![_*`~]|https?:\\/\\/| *\\n|$)/)\n\nconst captureText = (source: string): Parsed<NodeText> | null => {\n  const result = execText(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'text',\n      value: capture\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureText }\n","import { clearSource } from 'utils'\nimport {\n  captureBlockquote,\n  captureCodeBlock,\n  captureHeading,\n  captureHR,\n  captureHTML,\n  captureList,\n  captureNewLine,\n  captureParagraph,\n  captureTable\n} from 'blockParsers'\n\nimport {\n  captureCode,\n  captureEm,\n  captureEscape,\n  captureLineBreak,\n  captureLinks,\n  captureStrikethrough,\n  captureStrong,\n  captureText\n} from 'inlineParsers'\n\nimport { NodeItem, Parsed, Parser, Tokenizer } from 'models'\n\ntype ParsersList = { parser: Parser, priority: number }[]\n\nconst MDJ = () => {\n  const parsers: {\n    block: ParsersList\n    inline: ParsersList\n  } = {\n    block: [\n      { parser: captureNewLine, priority: 1000 },\n      { parser: captureHeading, priority: 900 },\n      { parser: captureHR, priority: 800 },\n      { parser: captureBlockquote, priority: 700 },\n      { parser: captureCodeBlock, priority: 600 },\n      { parser: captureTable, priority: 500 },\n      { parser: captureList, priority: 400 },\n      { parser: captureHTML, priority: 300 },\n      { parser: captureParagraph, priority: 0 }\n    ],\n    inline: [\n      { parser: captureEscape, priority: 1000 },\n      { parser: captureCode, priority: 900 },\n      { parser: captureStrong, priority: 800 },\n      { parser: captureEm, priority: 700 },\n      { parser: captureStrikethrough, priority: 600 },\n      { parser: captureLinks, priority: 500 },\n      { parser: captureLineBreak, priority: 400 },\n      { parser: captureText, priority: 0 }\n    ]\n  }\n\n  const blockLexer: Tokenizer = lexer('block')\n  const inlineLexer: Tokenizer = lexer('inline')\n\n  function addParser (type: 'block' | 'inline', parser: Parser, priority: number) {\n    parsers[type].push({parser, priority})\n    parsers[type] = parsers[type].sort((a, b) => b.priority - a.priority)\n  }\n\n  function pinchToken (type: 'block' | 'inline', source: string): Parsed<NodeItem> | null {\n    const l = parsers[type].length\n    let token\n    let newSource = ''\n\n    for (let i = 0; i < l; i += 1) {\n      const parser = parsers[type][i].parser\n      const parsed = type === 'block' ?\n        parser(source, blockLexer, inlineLexer) :\n        parser(source, inlineLexer)\n\n      if (parsed) {\n        newSource = parsed.newSource\n        token = parsed.token\n        break\n      }\n    }\n\n    if (!token) {\n      return null\n    }\n\n    return {\n      token,\n      newSource\n    }\n  }\n\n  function lexer (type: 'block' | 'inline') {\n    return (source: string): NodeItem[] => {\n      const tokens: NodeItem[] = []\n\n      while (source.length > 0) {\n        const {token = null, newSource = ''} = pinchToken(type, source) || {}\n\n        if (source === newSource || !token) {\n          throw new Error('Infinite loop on byte: ' + source.charCodeAt(0))\n        }\n\n        tokens.push(token)\n        source = newSource\n      }\n\n      return tokens\n    }\n  }\n\n  function prepareSource(source: string) {\n    return clearSource(source)\n  }\n\n  return {\n    parse: function parse(source: string) {\n      return blockLexer(prepareSource(source))\n    },\n    useInlineParser: function useInlineParser(parser: Parser, priority: number) {\n      addParser('inline', parser, priority)\n      return this\n    },\n    useBlockParser: function useBlockParser(parser: Parser, priority: number) {\n      addParser('block', parser, priority)\n      return this\n    }\n  }\n}\n\nexport { MDJ }\n","import { MDJ } from 'core/MDJ'\n\nconst parse = (source: string) => MDJ()\n  .parse(source)\n\nexport default MDJ\nexport { parse }\n"],"names":["curry","fn","arguments","length","inner","args","Array","prototype","slice","call","apply","bind","concat","exec","regExp","input","match","replace","from","to","split","matches","withWhat","what","test","clearSource","compose","a","b","fns","l","arg","result","i","map","execBlockquote","where","indexOf","clearBlockquote","captureBlockquote","source","tokenize","capture","children","type","token","newSource","substring","execCodeNormal","clearCode","execCodeFence","captureCodeNormal","language","value","captureCodeFence","captureCodeBlock","execHeading","execLHeading","getLevel","captureHeading","_","inlineLexer","level","rawValue","execHR","captureHR","execHTML","captureHTML","execList","matchItems","removeBullets","removeSpaces","matchBullet","precedeList","captureList","bull","parseChild","topItemsParsed","item","itemChildren","startToken","ordered","start","execNewLine","captureNewLine","execParagraph","removeLastLineBreak","captureParagraph","removeHeaderBounds","removeCellBounds","removeRowBounds","removeLastBounds","splitByLineBreak","isRight","isCenter","getTableHeader","trim","getTableRow","getCellAlign","getTableAlign","getNormalCells","lexer","cells","getNPCells","execNPTable","execTableNormal","captureTable","isNP","header","align","execCode","captureCode","execEm","captureEm","execEscape","captureEscape","execLineBreak","captureLineBreak","execAutolink","captureAutolink","at","text","href","charAt","testUrlStart","execUrl","captureUrl","execLink","captureLink","title","src","alt","captureLinks","execStrikethrough","captureStrikethrough","execStrong","captureStrong","execText","captureText","MDJ","parser","priority","parsers","push","sort","parsed","blockLexer","tokens","_a","_b","_c","Error","charCodeAt","block","inline","parse","prepareSource","useInlineParser","addParser","this","useBlockParser"],"mappings":"oMA6CA,IAAMA,GAAe,WACnB,GAAMC,GAAeC,UAAU,GACzBC,EAASF,EAAGE,OAEZC,EAAQ,WACZ,GAAIC,GAAOC,MAAMC,UAAUC,MAAMC,KAAKP,UAEtC,OAAIG,GAAKF,QAAUA,EACVF,EAAGS,MAAM,KAAML,GAEfD,EAAMO,KAAKD,MAAMN,GAAQ,MAAMQ,OAAOP,IAIjD,OAAOD,GAAMO,KAAKD,MAAMN,GAAQ,MAAMQ,OAAON,MAAMC,UAAUC,MAAMC,KAAKP,UAAW,MCzD/EW,EAAOb,EAAM,SAACc,EAAgBC,GAAmC,MAAAD,GAAOD,KAAKE,KCA7EC,EAAQhB,EAAM,SAACc,EAAgBC,GAAkB,MAAAA,GAAMC,MAAMF,SCA7DG,EAAUjB,EAAM,SAACkB,EAAuBC,EAAYJ,GAAkB,MAAAA,GAAME,QAAQC,EAAMC,KCA1FC,EAAQpB,EAAM,SAACc,EAAyBC,GAA4B,MAAAA,GAAMK,MAAMN,KCAhFO,EAAUrB,EAAM,SAACsB,EAAkBC,GAAiB,MAAAD,GAASE,KAAKD,KCFlEE,EAAc,SAACV,GAAkB,MAAAA,GAAME,QAAQ,WAAY,MAC9DA,QAAQ,MAAO,QACfA,QAAQ,UAAW,KACnBA,QAAQ,UAAW,MACnBA,QAAQ,SAAU,KCsBfS,GCxBS1B,EAAM,SAAC2B,EAAQC,GAAoB,MAAAD,KAAMC,IDwB/B,WACvB,GAAMC,GAAMvB,MAAMC,UAAUC,MAAMC,KAAKP,WACjC4B,EAAID,EAAI1B,OAAS,CAEvB,OAAO,UAAS4B,GAGd,IAAK,GAFDC,GAASD,EAEJE,EAAIH,EAAGG,GAAK,EAAGA,GAAK,EAC3BD,EAASH,EAAII,GAAGD,EAGlB,OAAOA,ME9BLE,EAAWlC,EAAM,SAAOC,EAAwCc,GAGpE,IAAK,GAFCiB,GAAS,GAAI1B,OAAMS,EAAMZ,QAEtB8B,EAAI,EAAGA,EAAIlB,EAAMZ,OAAQ8B,GAAK,EACrCD,EAAOC,GAAKhC,EAAGc,EAAMkB,GAAIA,EAAGlB,EAG9B,OAAOiB,KCVHG,GCFanC,EAAM,SAACuB,EAAca,GAAkB,MAAwB,KAAxBA,EAAMC,QAAQd,KDEjDV,EAAK,oGACtByB,EAAkBrB,EAAQ,WAAY,IACtCsB,EAAoB,SAACC,EAAgBC,GACzC,GAAkB,MAAdD,EAAO,GACT,MAAO,KAGT,IAAMR,GAASG,EAAeK,EAE9B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GAEnBW,EAAWF,EAASH,EAAgBI,GAMxC,OAJwB,KAApBC,EAASxC,QAAqC,cAArBwC,EAAS,GAAGC,OACvCD,EAAYA,EAAS,GAAqBA,WAI1CE,OACED,KAAM,aACND,SAAUF,EAASH,EAAgBI,KAErCI,UAAWN,EAAOO,UAAUL,EAAQvC,UE1BlC6C,EAAiBnC,EAAK,qBACtBoC,EAAYhC,EAAQ,UAAW,IAC/BiC,EAAgBrC,EAAK,8DAErBsC,EAAoB,SAACX,GACzB,GAAkB,MAAdA,EAAO,GACT,MAAO,KAGT,IAAMR,GAASgB,EAAeR,EAE9B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEa,OACED,KAAM,YACNQ,SAAU,GACVC,MAAOJ,EAAUP,IAEnBI,UAAWN,EAAOO,UAAUL,EAAQvC,UAIlCmD,EAAmB,SAACd,GACxB,GAAMR,GAASkB,EAAcV,EAE7B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAIvB,QACEa,OACED,KAAM,YACNQ,SANapB,EAAO,GAOpBqB,MANUrB,EAAO,IAQnBc,UAAWN,EAAOO,UAAUL,EAAQvC,UAIlCoD,EAAmB,SAACf,GACxB,MAAAW,GAAkBX,IAAWc,EAAiBd,ICjD1CgB,EAAc3C,EAAK,yCACnB4C,EAAe5C,EAAK,sCACpB6C,EAAW,SAAC3C,GAChB,MAAiB,MAAbA,EAAM,GACDA,EAAMZ,OAGE,MAAVY,EAAgB,EAAI,GAGvB4C,EAAiB,SAACnB,EAAgBoB,EAAQC,GAC9C,GAAM7B,GAAwB,MAAdQ,EAAO,IAAcgB,EAAYhB,IAAYiB,EAAajB,EAE1E,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjB8B,EAAQ9B,EAAO,GACf+B,EAAW/B,EAAO,EAExB,QACEa,OACED,KAAM,UACNkB,MAAOJ,EAASI,GAChBnB,SAAUkB,EAAYE,IAExBjB,UAAWN,EAAOO,UAAUL,EAAQvC,UC3BlC6D,EAASnD,EAAK,wCAEdoD,EAAY,SAACzB,GACjB,GAAMR,GAASgC,EAAOxB,EAEtB,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEa,OAASD,KAAM,MACfE,UAAWN,EAAOO,UAAUL,EAAQvC,UCblC+D,EAAWrD,EAAK,obAEhBsD,EAAc,SAAC3B,GACnB,GAAkB,MAAdA,EAAO,GACT,MAAO,KAGT,IAAMR,GAASkC,EAAS1B,EAExB,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEa,OACED,KAAM,OACNS,MAAOX,GAETI,UAAWN,EAAOO,UAAUL,EAAQvC,UCnBlCiE,EAAWvD,EAAK,2LAChBwD,EAAarD,EAAM,sEACnBsD,EAAgBrD,EAAQ,qBAAsB,IAC9CsD,EAAetD,EAAQ,QAAS,IAChCuD,EAAcxD,EAAM,SACpByD,EAAcxD,EAAQ,eAAgB,QAEtCyD,EAAc,SAAClC,EAAgBC,GACnC,GAAMT,GAASoC,EAAS5B,EAExB,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjB2C,EAAO3C,EAAO,GAEd4C,EAAalD,EAAQe,EAAUgC,EAAaF,EAAcD,GAC1DO,EAAiBR,EAAW3B,GAASR,IAAI,SAAC4C,GAC9C,GAAIC,GAAeH,EAAWE,EAM9B,OAJ4B,KAAxBC,EAAa5E,QAAyC,cAAzB4E,EAAa,GAAGnC,OAC/CmC,EAAgBA,EAAa,GAAqBpC,WAIlDC,KAAM,WACND,SAAUoC,KAIRC,EAAaR,EAAYG,EAQ/B,QACE9B,OAPAD,KAAM,OACNqC,UAAWD,EACXE,MAAOF,IAAeA,EAAW,GACjCrC,SAAUkC,GAKV/B,UAAWN,EAAOO,UAAUL,EAAQvC,UC1ClCgF,EAActE,EAAK,QAEnBuE,EAAiB,SAAC5C,GACtB,GAAMR,GAASmD,EAAY3C,EAE3B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEa,OAASD,KAAM,SACfE,UAAWN,EAAOO,UAAUL,EAAQvC,UCblCkF,EAAgBxE,EAAK,wBACrByE,EAAsBrE,EAAQ,MAAO,KAErCsE,EAAmB,SAAC/C,EAAgBoB,EAAQC,GAChD,GAAM7B,GAASqD,EAAc7C,EAE7B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjB+B,EAAW/B,EAAO,EAExB,QACEa,OACED,KAAM,YACND,SAAUkB,EAAYyB,EAAoBvB,KAE5CjB,UAAWN,EAAOO,UAAUL,EAAQvC,UCjBlCqF,EAAqBvE,EAAQ,eAAgB,IAC7CwE,EAAmBxE,EAAQ,mBAAoB,IAC/CyE,EAAkBzE,EAAQ,aAAc,IACxCqE,EAAsBrE,EAAQ,MAAO,KACrC0E,EAAmB1E,EAAQ,iBAAkB,IAC7C2E,EAAmBxE,EAAM,MACzByE,EAAUxE,EAAQ,aAClByE,EAAWzE,EAAQ,cAEnB0E,EAAiB,SAACvD,GAA6B,MAAAgD,GAAmBhD,GAAQpB,MAVjE,UAU+Ec,IAAI,SAAA4C,GAAQ,MAAAA,GAAKkB,UACzGC,EAAcvE,EAAQN,EAXb,UAW4BqE,GACrCS,EAAe,SAACnF,GACpB,MAAI8E,GAAQ9E,GACH,QACE+E,EAAS/E,GACX,SAEA,QAGLoF,EAAgB,SAAC3D,GAAyC,MAAAkD,GAAgBlD,GAAQpB,MArBzE,UAqBuFc,IAAIgE,IACpGE,EAAiB,SAACC,EAAkBC,GACxC,MAAA5E,GAAQQ,EAAIR,EAAQQ,EAAImE,GAAQJ,IAAeL,EAAkBD,GAAkBW,IAC/EC,EAAa,SAACF,EAAkBC,GACpC,MAAA5E,GAAQQ,EAAIR,EAAQQ,EAAImE,GAAQjF,EAzBnB,YAyBoCwE,EAAkBN,GAAqBgB,IAEpFE,EAAc3F,EAAK,iEACnB4F,GAAkB5F,EAAK,6DAEvB6F,GAAe,SAAClE,EAAgBoB,EAAQC,GAC5C,GAAI7B,GAASwE,EAAYhE,GACrBmE,GAAO,CAOX,IALK3E,IACHA,EAASyE,GAAgBjE,GACzBmE,GAAO,IAGJ3E,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjB4E,EAAS5E,EAAO,GAChB6E,EAAQ7E,EAAO,GACfsE,EAAQtE,EAAO,EAErB,OAAKU,IAKHG,OACED,KAAM,QACNgE,OAAQb,EAAea,GACvBC,MAAOV,EAAcU,GACrBP,MAAOK,EAAOJ,EAAW1C,EAAayC,GAASF,EAAevC,EAAayC,IAE7ExD,UAAWN,EAAOO,UAAUL,EAAQvC,SAV7B,MCjDL2G,GAAWjG,EAAK,oCAChBkG,GAAc,SAACvE,GACnB,GAAkB,MAAdA,EAAO,GACP,MAAO,KAGX,IAAMR,GAAS8E,GAAStE,EAExB,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAGvB,QACEa,OACED,KAAM,OACNS,MALSrB,EAAO,IAOlBc,UAAWN,EAAOO,UAAUL,EAAQvC,UCpBlC6G,GAASnG,EAAK,yDACdoG,GAAY,SAACzE,EAAgBqB,GACjC,GAAkB,MAAdrB,EAAO,IAA4B,MAAdA,EAAO,GAC5B,MAAO,KAGX,IAAMR,GAASgF,GAAOxE,EAEtB,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBL,EAAIK,EAAO,EAGjB,QACEa,OACED,KAAM,KACND,SAAUkB,EALJ7B,EAAO,IAKcL,IAE7BmB,UAAWN,EAAOO,UAAUL,EAAQvC,UCrBlC+G,GAAarG,EAAK,gCAClBsG,GAAgB,SAAC3E,GACrB,GAAkB,OAAdA,EAAO,GACP,MAAO,KAGX,IAAMR,GAASkF,GAAW1E,EAE1B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEa,OACED,KAAM,OACNS,MAAOX,GAETI,UAAWN,EAAOO,UAAUL,EAAQvC,UCnBlCiH,GAAgBvG,EAAK,iBACrBwG,GAAmB,SAAC7E,GACxB,GAAMR,GAASoF,GAAc5E,EAE7B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEa,OACED,KAAM,MAERE,UAAWN,EAAOO,UAAUL,EAAQvC,UCdlCmH,GAAezG,EAAK,4BACpB0G,GAAkB,SAAC/E,GACvB,GAAkB,MAAdA,EAAO,GACT,MAAO,KAGT,IAAMR,GAASsF,GAAa9E,EAE5B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBwF,EAAKxF,EAAO,GACdyF,EAAOzF,EAAO,GACd0F,EAAO,EAUX,OAPW,MAAPF,GACFC,EAA0B,MAAnBA,EAAKE,OAAO,GAAaF,EAAK1E,UAAU,GAAK0E,EACpDC,EAAO,UAAYD,GAEnBC,EAAOD,GAIP5E,OACED,KAAM,OACN8E,OACA/E,WAEIC,KAAM,OACNS,MAAOoE,KAIb3E,UAAWN,EAAOO,UAAUL,EAAQvC,UAIlCyH,GAAevG,EAAQ,SACvBwG,GAAUhH,EAAK,wCACfiH,GAAa,SAACtF,GAClB,IAAKoF,GAAapF,GAChB,MAAO,KAGT,IAAMR,GAAS6F,GAAQrF,EAEvB,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjByF,EAAOzF,EAAO,EAEpB,QACEa,OACED,KAAM,OACN8E,KAAMD,EACN9E,WAEIC,KAAM,OACNS,MAAOoE,KAIb3E,UAAWN,EAAOO,UAAUL,EAAQvC,UAKlC4H,GAAWlH,EAAK,mGAChBmH,GAAc,SAACxF,EAAgBqB,GACnC,GAAkB,MAAdrB,EAAO,IAA4B,MAAdA,EAAO,GAC9B,MAAO,KAGT,IACIK,GADEb,EAAS+F,GAASvF,EAGxB,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjByF,EAAOzF,EAAO,GACd0F,EAAO1F,EAAO,GACdiG,EAAQjG,EAAO,EAkBrB,OAfEa,GADc,MAAZ4E,EAAK,IAEL7E,KAAM,QACNsF,IAAKR,EACLS,IAAKV,EACLQ,UAIArF,KAAM,OACN8E,OACAO,QACAtF,SAAUkB,EAAY4D,KAKxB5E,QACAC,UAAWN,EAAOO,UAAUL,EAAQvC,UAKlCiI,GAAe,SAAC5F,EAAgBqB,GACpC,MAAA0D,IAAgB/E,IAAWsF,GAAWtF,IAAWwF,GAAYxF,EAAQqB,IClHjEwE,GAAoBxH,EAAK,2BACzByH,GAAuB,SAAC9F,EAAgBqB,GAC5C,GAAkB,MAAdrB,EAAO,GACP,MAAO,KAGX,IAAMR,GAASqG,GAAkB7F,EAEjC,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAGvB,QACEa,OACED,KAAM,gBACND,SAAUkB,EALG7B,EAAO,KAOtBc,UAAWN,EAAOO,UAAUL,EAAQvC,UCpBlCoI,GAAa1H,EAAK,kDAClB2H,GAAgB,SAAChG,EAAgBqB,GACrC,GAAkB,MAAdrB,EAAO,IAA4B,MAAdA,EAAO,GAC5B,MAAO,KAGX,IAAMR,GAASuG,GAAW/F,EAE1B,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,GACjBL,EAAIK,EAAO,EAGjB,QACEa,OACED,KAAM,SACND,SAAUkB,EALJ7B,EAAO,IAKcL,IAE7BmB,UAAWN,EAAOO,UAAUL,EAAQvC,UCrBlCsI,GAAW5H,EAAK,+CAEhB6H,GAAc,SAAClG,GACnB,GAAMR,GAASyG,GAASjG,EAExB,KAAKR,EACH,MAAO,KAGT,IAAMU,GAAUV,EAAO,EAEvB,QACEa,OACED,KAAM,OACNS,MAAOX,GAETI,UAAWN,EAAOO,UAAUL,EAAQvC,UCQlCwI,GAAM,WA+BV,WAAoB/F,EAA0BgG,EAAgBC,GAC5DC,EAAQlG,GAAMmG,MAAMH,SAAQC,aAC5BC,EAAQlG,GAAQkG,EAAQlG,GAAMoG,KAAK,SAACrH,EAAGC,GAAM,MAAAA,GAAEiH,SAAWlH,EAAEkH,WAG9D,WAAqBjG,EAA0BJ,GAK7C,IAAK,GAHDK,GADEf,EAAIgH,EAAQlG,GAAMzC,OAEpB2C,EAAY,GAEPb,EAAI,EAAGA,EAAIH,EAAGG,GAAK,EAAG,CAC7B,GAAM2G,GAASE,EAAQlG,GAAMX,GAAG2G,OAC1BK,EAAkB,UAATrG,EACbgG,EAAOpG,EAAQ0G,EAAYrF,GAC3B+E,EAAOpG,EAAQqB,EAEjB,IAAIoF,EAAQ,CACVnG,EAAYmG,EAAOnG,UACnBD,EAAQoG,EAAOpG,KACf,QAIJ,MAAKA,IAKHA,QACAC,aALO,KASX,WAAgBF,GACd,MAAO,UAACJ,GAGN,IAFA,GAAM2G,MAEC3G,EAAOrC,OAAS,GAAG,CAClB,GAAAiJ,cAACC,UAAAxG,oBAAcyG,cAAAxG,iBAErB,IAAIN,IAAWM,IAAcD,EAC3B,KAAM,IAAI0G,OAAM,0BAA4B/G,EAAOgH,WAAW,GAGhEL,GAAOJ,KAAKlG,GACZL,EAASM,EAGX,MAAOqG,IAIX,WAAuB3G,GACrB,MAAOf,GAAYe,GAnFrB,GAAMsG,IAIJW,QACIb,OAAQxD,EAAgByD,SAAU,MAClCD,OAAQjF,EAAgBkF,SAAU,MAClCD,OAAQ3E,EAAW4E,SAAU,MAC7BD,OAAQrG,EAAmBsG,SAAU,MACrCD,OAAQrF,EAAkBsF,SAAU,MACpCD,OAAQlC,GAAcmC,SAAU,MAChCD,OAAQlE,EAAamE,SAAU,MAC/BD,OAAQzE,EAAa0E,SAAU,MAC/BD,OAAQrD,EAAkBsD,SAAU,IAExCa,SACId,OAAQzB,GAAe0B,SAAU,MACjCD,OAAQ7B,GAAa8B,SAAU,MAC/BD,OAAQJ,GAAeK,SAAU,MACjCD,OAAQ3B,GAAW4B,SAAU,MAC7BD,OAAQN,GAAsBO,SAAU,MACxCD,OAAQR,GAAcS,SAAU,MAChCD,OAAQvB,GAAkBwB,SAAU,MACpCD,OAAQF,GAAaG,SAAU,KAI/BK,EAAwB7C,EAAM,SAC9BxC,EAAyBwC,EAAM,SA0DrC,QACEsD,MAAO,SAAenH,GACpB,MAAO0G,GAAWU,EAAcpH,KAElCqH,gBAAiB,SAAyBjB,EAAgBC,GAExD,MADAiB,GAAU,SAAUlB,EAAQC,GACrBkB,MAETC,eAAgB,SAAwBpB,EAAgBC,GAEtD,MADAiB,GAAU,QAASlB,EAAQC,GACpBkB,QC3HPJ,GAAQ,SAACnH,GAAmB,MAAAmG,MAC/BgB,MAAMnH"}
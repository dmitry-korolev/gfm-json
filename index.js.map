{"version":3,"file":"index.js","sources":["src/utils/curry.ts","src/utils/clearSource.ts","src/utils/compose.ts","src/utils/exec.ts","src/utils/equals.ts","src/utils/map.ts","src/utils/match.ts","src/utils/matches.ts","src/utils/replace.ts","src/utils/split.ts","src/utils/trim.ts","src/utils/startsWith.ts","src/blockParsers/captureBlockquote.ts","src/blockParsers/captureCodeBlock.ts","src/blockParsers/captureHeading.ts","src/blockParsers/captureHR.ts","src/blockParsers/captureHTML.ts","src/blockParsers/captureList.ts","src/blockParsers/captureNewLine.ts","src/blockParsers/captureParagraph.ts","src/blockParsers/captureTable.ts","src/inlineParsers/captureCode.ts","src/inlineParsers/captureEm.ts","src/inlineParsers/captureEscape.ts","src/inlineParsers/captureLinebreak.ts","src/inlineParsers/captureLinks.ts","src/inlineParsers/captureStrikethrough.ts","src/inlineParsers/captureStrong.ts","src/inlineParsers/captureText.ts","src/core/MDJ.ts","src/index.ts"],"sourcesContent":["// Yep, interfaces are stolen from ramda types\ninterface CurriedFunction2<T1, T2, R> {\n  (t1: T1): (t2: T2) => R\n  (t1: T1, t2: T2): R\n}\n\ninterface CurriedFunction3<T1, T2, T3, R> {\n  (t1: T1): CurriedFunction2<T2, T3, R>\n  (t1: T1, t2: T2): (t3: T3) => R\n  (t1: T1, t2: T2, t3: T3): R\n}\n\ninterface CurriedFunction4<T1, T2, T3, T4, R> {\n  (t1: T1): CurriedFunction3<T2, T3, T4, R>\n  (t1: T1, t2: T2): CurriedFunction2<T3, T4, R>\n  (t1: T1, t2: T2, t3: T3): (t4: T4) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4): R\n}\n\ninterface CurriedFunction5<T1, T2, T3, T4, T5, R> {\n  (t1: T1): CurriedFunction4<T2, T3, T4, T5, R>\n  (t1: T1, t2: T2): CurriedFunction3<T3, T4, T5, R>\n  (t1: T1, t2: T2, t3: T3): CurriedFunction2<T4, T5, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4): (t5: T5) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5): R\n}\n\ninterface CurriedFunction6<T1, T2, T3, T4, T5, T6, R> {\n  (t1: T1): CurriedFunction5<T2, T3, T4, T5, T6, R>\n  (t1: T1, t2: T2): CurriedFunction4<T3, T4, T5, T6, R>\n  (t1: T1, t2: T2, t3: T3): CurriedFunction3<T4, T5, T6, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4): CurriedFunction2<T5, T6, R>\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5): (t6: T6) => R\n  (t1: T1, t2: T2, t3: T3, t4: T4, t5: T5, t6: T6): R\n}\n\ninterface Curry {\n  <T1, T2, TResult>(fn: (a: T1, b: T2) => TResult, args?: any): CurriedFunction2<T1,T2, TResult>\n  <T1, T2, T3, TResult>(fn: (a: T1, b: T2, c: T3) => TResult, args?: any): CurriedFunction3<T1,T2, T3, TResult>\n  <T1, T2, T3, T4, TResult>(fn: (a: T1, b: T2, c: T3, d: T4) => TResult, args?: any): CurriedFunction4<T1,T2, T3, T4, TResult>\n  <T1, T2, T3, T4, T5, TResult>(fn: (a: T1, b: T2, c: T3, d: T4, e: T5) => TResult, args?: any): CurriedFunction5<T1,T2, T3, T4, T5, TResult>\n  <T1, T2, T3, T4, T5, T6, TResult>(fn: (a: T1, b: T2, c: T3, d: T4, e: T5, f: T6) => TResult, args?: any): CurriedFunction6<T1,T2, T3, T4, T5, T6, TResult>\n  (fn: Function): Function\n}\n\nconst curry: Curry = function() {\n  const fn: Function = arguments[0]\n  const length = fn.length\n\n  const inner = function() {\n    let args = Array.prototype.slice.call(arguments)\n\n    if (args.length >= length) {\n      return fn.apply(null, args)\n    } else {\n      return inner.bind.apply(inner, [null].concat(args))\n    }\n  }\n\n  return inner.bind.apply(inner, [null].concat(Array.prototype.slice.call(arguments, 1)))\n}\n\nexport { curry }\n","const clearSource = (input: string) => input.replace(/\\r\\n|\\r/g, '\\n')\n  .replace(/\\t/g, '    ')\n  .replace(/\\u00a0/g, ' ')\n  .replace(/\\u2424/g, '\\n')\n  .replace(/^ +$/gm, '')\n\nexport { clearSource }\n","interface Compose {\n  <V0, T1>(fn0: (x0: V0) => T1): (x0: V0) => T1;\n  <V0, V1, T1>(fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T1;\n  <V0, V1, V2, T1>(fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T1;\n\n  <V0, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0) => T1): (x0: V0) => T2;\n  <V0, V1, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T2;\n  <V0, V1, V2, T1, T2>(fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T2;\n\n  <V0, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T3;\n  <V0, V1, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T3;\n  <V0, V1, V2, T1, T2, T3>(fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T3;\n\n  <V0, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T4;\n  <V0, V1, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T4;\n  <V0, V1, V2, T1, T2, T3, T4>(fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T4;\n\n  <V0, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T5;\n  <V0, V1, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T5;\n  <V0, V1, V2, T1, T2, T3, T4, T5>(fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T5;\n\n  <V0, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x: V0) => T1): (x: V0) => T6;\n  <V0, V1, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1) => T1): (x0: V0, x1: V1) => T6;\n  <V0, V1, V2, T1, T2, T3, T4, T5, T6>(fn5: (x: T5) => T6, fn4: (x: T4) => T5, fn3: (x: T3) => T4, fn2: (x: T2) => T3, fn1: (x: T1) => T2, fn0: (x0: V0, x1: V1, x2: V2) => T1): (x0: V0, x1: V1, x2: V2) => T6;\n}\n\nconst compose: Compose = function () {\n  const fns = Array.prototype.slice.call(arguments)\n  const l = fns.length - 1\n\n  return function(arg: any) {\n    let result = arg\n\n    for (let i = l; i >= 0; i -= 1) {\n      result = fns[i](result)\n    }\n\n    return result\n  }\n}\n\nexport { compose }\n","import { curry } from 'utils'\n\nconst exec = curry((regExp: RegExp, input: string): string[] | null => regExp.exec(input))\n\nexport { exec }\n\n","import { curry } from 'utils'\n\nconst equals = curry((a: any, b: any): boolean => a === b)\n\nexport { equals }\n","import { curry } from 'utils'\n\ninterface Map {\n  <V, R>(fn: (x0: V, x1: number, x2: V[]) => R): (input: V[]) => R[]\n  <V, R>(fn: (x0: V, x1: number, x2: V[]) => R, input: V[]): R[]\n}\n\nconst map: Map = curry(<V, R>(fn: (x0: V, x1: number, x2: V[]) => R , input: V[]) => {\n  const result = new Array(input.length)\n\n  for (let i = 0; i < input.length; i += 1) {\n    result[i] = fn(input[i], i, input)\n  }\n\n  return result\n})\n\nexport { map }\n","import { curry } from 'utils'\n\nconst match = curry((regExp: RegExp, input: string) => input.match(regExp) || [])\n\nexport { match }\n","import { curry } from 'utils'\n\nconst matches = curry((withWhat: RegExp, what: string) => withWhat.test(what))\n\nexport { matches }\n","import { curry } from 'utils'\n\nconst replace = curry((from: string | RegExp, to: string, input: string) => input.replace(from, to))\n\nexport { replace }\n","import { curry } from 'utils'\n\nconst split = curry((regExp: RegExp | string, input: string): string[] => input.split(regExp))\n\nexport { split }\n","const trim = (source: string) => source.trim()\n\nexport { trim }\n","import { curry } from 'utils'\n\nconst startsWith = curry((what: string, where: string) => where.indexOf(what) === 0)\n\nexport { startsWith }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeBlockquote, Tokenizer, NodeParagraph } from 'models'\n\nconst execBlockquote = exec(/^( *>[^\\n]+(\\n(?! *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +[\"(]([^\\n]+)[\")])? *(?:\\n+|$))[^\\n]+)*\\n*)+/)\nconst clearBlockquote = replace(/^ *> ?/gm, '')\nconst captureBlockquote = (source: string, tokenize: Tokenizer): Parsed<NodeBlockquote> | null => {\n  if (source[0] !== '>') {\n    return null\n  }\n\n  const result = execBlockquote(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  let children = tokenize(clearBlockquote(capture))\n\n  if (children.length === 1 && children[0].type === 'paragraph') {\n    children = (children[0] as NodeParagraph).children\n  }\n\n  return {\n    token: {\n      type: 'blockquote',\n      children: tokenize(clearBlockquote(capture))\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureBlockquote }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeCodeBlock } from 'models'\n\nconst execCodeNormal = exec(/^( {4}[^\\n]+\\n*)+/)\nconst clearCode = replace(/^ {4}/gm, '')\nconst execCodeFence = exec(/^ *(`{3,}|~{3,})[ \\.]*(\\S+)? *\\n([\\s\\S]*?)\\s*\\1 *(?:\\n+|$)/)\n\nconst captureCodeNormal = (source: string): Parsed<NodeCodeBlock> | null => {\n  if (source[0] !== '`') {\n    return null\n  }\n\n  const result = execCodeNormal(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'codeblock',\n      language: '',\n      value: clearCode(capture)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst captureCodeFence = (source: string): Parsed<NodeCodeBlock> | null => {\n  const result = execCodeFence(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const language = result[2]\n  const value = result[3]\n\n  return {\n    token: {\n      type: 'codeblock',\n      language,\n      value\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst captureCodeBlock = (source: string): Parsed<NodeCodeBlock> | null =>\n  captureCodeNormal(source) || captureCodeFence(source)\nexport { captureCodeBlock }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeHeading, Tokenizer } from 'models'\n\nconst execHeading = exec(/^ *(#{1,6}) +([^\\n]+?) *#* *(?:\\n+|$)/)\nconst execLHeading = exec(/^([^\\n]+)\\n *([=-]){2,} *(?:\\n+|$)/)\nconst getLevel = (input: string): number => {\n  if (input[0] === '#') {\n    return input.length\n  }\n\n  return input[0] === '=' ? 1 : 2\n}\n\nconst captureHeading = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeHeading> | null => {\n  const isNormal = source[0] === '#'\n  const result = (isNormal && execHeading(source)) || execLHeading(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const level = isNormal ? result[1] : result[2]\n  const rawValue = isNormal ? result[2] : result[1]\n\n  return {\n    token: {\n      type: 'heading',\n      level: getLevel(level),\n      children: inlineLexer(rawValue)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\n\nexport { captureHeading }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeHR } from 'models'\n\nconst execHR = exec(/^ *(?:\\*{3,}|-{3,}|_{3,}) *(?:\\n+|$)/)\n\nconst captureHR = (source: string): Parsed<NodeHR> | null => {\n  const result = execHR(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: { type: 'hr' },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureHR }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeHTML } from 'models'\n\nconst execHTML = exec(/^(?:<!--[\\s\\S]*?--> *(?:\\n|\\s*$)|<((?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\b)\\w+(?!:\\/|[^\\w\\s@]*@)\\b)[\\s\\S]+?<\\/\\1> *(?:\\n{2,}|\\s*$)|<(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\b)\\w+(?!:\\/|[^\\w\\s@]*@)\\b(?:\"[^\"]*\"|'[^']*'|[^'\">])*?> *(?:\\n{2,}|\\s*$))/)\n\nconst captureHTML = (source: string): Parsed<NodeHTML> | null => {\n  if (source[0] !== '<') {\n    return null\n  }\n\n  const result = execHTML(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'html',\n      value: capture\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureHTML }\n","import { exec, match, replace, compose } from 'utils'\n\nimport { Parsed, NodeList, NodeListItem, Tokenizer, NodeParagraph } from 'models'\nimport {  } from '../utils/match'\n\nconst execList = exec(/^( *)((?:[*+-]|\\d+\\.)) [\\s\\S]+?(?:\\n+(?=\\1?(?:[-*_] *){3,}(?:\\n+|$))|\\n+(?= *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +[\"(]([^\\n]+)[\")])? *(?:\\n+|$))|\\n{2,}(?! )(?!\\1(?:[*+-]|\\d+\\.) )\\n*|\\s*$)/)\nconst matchItems = match(/^( *)((?:[*+-]|\\d+\\.)) [^\\n]*(?:\\n(?!\\1(?:[*+-]|\\d+\\.) )[^\\n]*)*/gm)\nconst removeBullets = replace(/^ *([*+-]|\\d+\\.) +/, '')\nconst removeSpaces = replace(/^ */gm, '')\nconst matchBullet = match(/^(\\d)/)\nconst precedeList = replace(/\\n(?=\\d*\\. )/, '\\n\\n')\n\nconst captureList = (source: string, tokenize: Tokenizer): Parsed<NodeList> | null=> {\n  const result = execList(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const bull = result[2]\n\n  const parseChild = compose(tokenize, precedeList, removeSpaces, removeBullets)\n  const topItemsParsed = matchItems(capture).map((item): NodeListItem => {\n    let itemChildren = parseChild(item)\n\n    if (itemChildren.length === 1 && itemChildren[0].type === 'paragraph') {\n      itemChildren = (itemChildren[0] as NodeParagraph).children\n    }\n\n    return {\n      type: 'listitem',\n      children: itemChildren\n    }\n  })\n\n  const startToken = matchBullet(bull)\n  const token: NodeList = {\n    type: 'list',\n    ordered: !!startToken,\n    start: startToken && +startToken[1],\n    children: topItemsParsed\n  }\n\n  return {\n    token,\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureList }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeSpace } from 'models'\n\nconst execNewLine = exec(/^\\n+/)\n\nconst captureNewLine = (source: string): Parsed<NodeSpace> | null => {\n  const result = execNewLine(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: { type: 'space' },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureNewLine }\n","import { exec, replace } from 'utils'\n\nimport { Parsed, NodeParagraph, Tokenizer } from 'models'\n\nconst execParagraph = exec(/^((?:[^\\n]+\\n?)+)\\n*/)\nconst removeLastLineBreak = replace(/\\n$/, ' ')\n\nconst captureParagraph = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeParagraph> | null => {\n  const result = execParagraph(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const rawValue = result[1]\n\n  return {\n    token: {\n      type: 'paragraph',\n      children: inlineLexer(removeLastLineBreak(rawValue))\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureParagraph }\n","import { exec, matches, replace, compose, map, split, trim } from 'utils'\n\nimport { Parsed, NodeTable, Tokenizer, NodeItem } from 'models'\n\nconst rowSep = / *\\| */\nconst removeHeaderBounds = replace(/^ *| *\\| *$/g, '')\nconst removeCellBounds = replace(/^ *\\| *| *\\| *$/g, '')\nconst removeRowBounds = replace(/^ *|\\| *$/g, '')\nconst removeLastLineBreak = replace(/\\n$/, ' ')\nconst removeLastBounds = replace(/(?: *\\| *)?\\n$/, '')\nconst splitByLineBreak = split('\\n')\nconst isRight = matches(/^ *-+: *$/)\nconst isCenter = matches(/^ *:-+: *$/)\n\nconst splitRow = (input: string) => {\n  const result: string[] = []\n  let cell = 0\n\n  for(let i = 0; i < input.length; i += 1) {\n    if (input[i] === '|' && input[i - 1] !== '`' && input[i - 1] !== '\\\\') {\n      cell++\n      continue\n    }\n    result[cell] = (result[cell] || '') + input[i]\n  }\n\n  return map(trim, result)\n}\n\nconst getTableHeader = (lexer: Tokenizer, source: string): NodeItem[][] =>\n  compose(map(lexer), splitRow, removeHeaderBounds)(source)\nconst getTableRow = compose(splitRow, removeCellBounds)\nconst getCellAlign = (input: string): string | null => {\n  if (isRight(input)) {\n    return 'right'\n  } else if (isCenter(input)) {\n    return 'center'\n  } else {\n    return 'left'\n  }\n}\nconst getTableAlign = compose(map(getCellAlign), split(rowSep), removeRowBounds)\nconst getNormalCells = (lexer: Tokenizer, cells: string): NodeItem[][][] =>\n  compose(map(compose(map(lexer), getTableRow)), splitByLineBreak, removeLastBounds)(cells)\nconst getNPCells = (lexer: Tokenizer, cells: string): NodeItem[][][] =>\n  compose(map(compose(map(lexer), split(rowSep))), splitByLineBreak, removeLastLineBreak)(cells)\n\nconst execNPTable = exec(/^ *(\\S.*\\|.*)\\n *([-:]+ *\\|[-| :]*)\\n((?:.*\\|.*(?:\\n|$))*)\\n*/)\nconst execTableNormal = exec(/^ *\\|(.+)\\n *\\|( *[-:]+[-| :]*)\\n((?: *\\|.*(?:\\n|$))*)\\n*/)\n\nconst captureTable = (source: string, _: any, inlineLexer: Tokenizer): Parsed<NodeTable> | null => {\n  let result = execNPTable(source)\n  let isNP = true\n\n  if (!result) {\n    result = execTableNormal(source)\n    isNP = false\n  }\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const header = result[1]\n  const align = result[2]\n  const cells = result[3]\n\n  if (!capture) {\n    return null\n  }\n\n  return {\n    token: {\n      type: 'table',\n      header: getTableHeader(inlineLexer, header),\n      align: getTableAlign(align),\n      cells: isNP ? getNPCells(inlineLexer, cells) : getNormalCells(inlineLexer, cells)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureTable }\n","import { exec } from 'utils'\n\nimport { NodeCode, Parsed } from 'models'\n\nconst execCode = exec(/^(`+)\\s*([\\s\\S]*?[^`])\\s*\\1(?!`)/)\nconst captureCode = (source: string): Parsed<NodeCode> | null => {\n  if (source[0] !== '`') {\n      return null\n  }\n\n  const result = execCode(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const code = result[2]\n\n  return {\n    token: {\n      type: 'code',\n      value: code\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureCode }\n","import { exec } from 'utils'\n\nimport { NodeEm, Parsed, Tokenizer } from 'models'\n\nconst execEm = exec(/^\\b_((?:[^_]|__)+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/)\nconst captureEm = (source: string, inlineLexer: Tokenizer): Parsed<NodeEm> | null => {\n  if (source[0] !== '_' && source[0] !== '*') {\n      return null\n  }\n\n  const result = execEm(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const a = result[1]\n  const b = result[2]\n\n  return {\n    token: {\n      type: 'em',\n      children: inlineLexer(b || a)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureEm }\n","import { exec } from 'utils'\n\nimport { NodeText, Parsed } from 'models'\n\nconst execEscape = exec(/^\\\\([\\\\`*{}[\\]()#+\\-.!_>~|])/)\nconst captureEscape = (source: string): Parsed<NodeText> | null => {\n  if (source[0] !== '\\\\') {\n      return null\n  }\n\n  const result = execEscape(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'text',\n      value: capture\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureEscape }\n","import { exec } from 'utils'\n\nimport { NodeLineBreak, Parsed } from 'models'\n\nconst execLineBreak = exec(/^ *\\n(?!\\s*$)/)\nconst captureLineBreak = (source: string): Parsed<NodeLineBreak> | null => {\n  const result = execLineBreak(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'br'\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureLineBreak }\n","import { exec, matches } from 'utils'\n\nimport { Parsed, NodeLink, Tokenizer, NodeImage } from 'models'\n\nconst execAutolink = exec(/^<([^ >]+(@|:\\/)[^ >]+)>/)\nconst captureAutolink = (source: string): Parsed<NodeLink> | null => {\n  if (source[0] !== '<') {\n    return null\n  }\n\n  const result = execAutolink(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const at = result[2]\n  let text = result[1]\n  let href = ''\n\n\n  if (at === '@') {\n    text = text.charAt(6) === ':' ? text.substring(7) : text\n    href = 'mailto:' + text\n  } else {\n    href = text\n  }\n\n  return {\n    token: {\n      type: 'link',\n      href,\n      children: [\n        {\n          type: 'text',\n          value: text\n        }\n      ]\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nconst testUrlStart = matches(/^http/)\nconst execUrl = exec(/^(https?:\\/\\/[^\\s<]+[^<.,:;\"')\\]\\s])/)\nconst captureUrl = (source: string): Parsed<NodeLink> | null => {\n  if (!testUrlStart(source)) {\n    return null\n  }\n\n  const result = execUrl(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const text = result[1]\n\n  return {\n    token: {\n      type: 'link',\n      href: text,\n      children: [\n        {\n          type: 'text',\n          value: text\n        }\n      ]\n    },\n    newSource: source.substring(capture.length)\n  }\n\n}\n\nconst execLink = exec(/^!?\\[((?:\\[[^\\]]*\\]|[^[\\]]|\\](?=[^[]*\\]))*)\\]\\(\\s*<?([\\s\\S]*?)>?(?:\\s+['\"]([\\s\\S]*?)['\"])?\\s*\\)/)\nconst captureLink = (source: string, inlineLexer: Tokenizer): Parsed<NodeLink | NodeImage> | null => {\n  if (source[0] !== '[' && source[0] !== '!') {\n    return null\n  }\n\n  const result = execLink(source)\n  let token: NodeLink | NodeImage\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const text = result[1]\n  const href = result[2]\n  const title = result[3]\n\n  if (text[0] === '!') {\n    token = {\n      type: 'image',\n      src: href,\n      alt: text\n    }\n  } else {\n    token = {\n      type: 'link',\n      href,\n      children: inlineLexer(text)\n    }\n  }\n\n  if (title) {\n    token.title = title\n  }\n\n  return {\n    token,\n    newSource: source.substring(capture.length)\n  }\n\n}\n\nconst captureLinks = (source: string, inlineLexer: Tokenizer): Parsed<NodeLink | NodeImage> | null =>\n  captureAutolink(source) || captureUrl(source) || captureLink(source, inlineLexer)\n\nexport { captureLinks }\n","import { exec } from 'utils'\n\nimport { NodeStrikethrough, Parsed, Tokenizer } from 'models'\n\nconst execStrikethrough = exec(/^~~(?=\\S)([\\s\\S]*?\\S)~~/)\nconst captureStrikethrough = (source: string, inlineLexer: Tokenizer): Parsed<NodeStrikethrough> | null => {\n  if (source[0] !== '~') {\n      return null\n  }\n\n  const result = execStrikethrough(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const rawValue = result[1]\n\n  return {\n    token: {\n      type: 'strikethrough',\n      children: inlineLexer(rawValue)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureStrikethrough }\n","import { exec } from 'utils'\n\nimport { NodeStrong, Parsed, Tokenizer } from 'models'\n\nconst execStrong = exec(/^__([\\s\\S]+?)__(?!_)|^\\*\\*([\\s\\S]+?)\\*\\*(?!\\*)/)\nconst captureStrong = (source: string, inlineLexer: Tokenizer): Parsed<NodeStrong> | null => {\n  if (source[0] !== '_' && source[0] !== '*') {\n      return null\n  }\n\n  const result = execStrong(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n  const a = result[1]\n  const b = result[2]\n\n  return {\n    token: {\n      type: 'strong',\n      children: inlineLexer(b || a)\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureStrong }\n","import { exec } from 'utils'\n\nimport { Parsed, NodeText } from 'models'\n\nconst execText = exec(/^[\\s\\S]+?(?=[\\\\<![_*`~]|https?:\\/\\/| *\\n|$)/)\n\nconst captureText = (source: string): Parsed<NodeText> | null => {\n  const result = execText(source)\n\n  if (!result) {\n    return null\n  }\n\n  const capture = result[0]\n\n  return {\n    token: {\n      type: 'text',\n      value: capture\n    },\n    newSource: source.substring(capture.length)\n  }\n}\n\nexport { captureText }\n","import { clearSource } from 'utils'\nimport {\n  captureBlockquote,\n  captureCodeBlock,\n  captureHeading,\n  captureHR,\n  captureHTML,\n  captureList,\n  captureNewLine,\n  captureParagraph,\n  captureTable\n} from 'blockParsers'\n\nimport {\n  captureCode,\n  captureEm,\n  captureEscape,\n  captureLineBreak,\n  captureLinks,\n  captureStrikethrough,\n  captureStrong,\n  captureText\n} from 'inlineParsers'\n\nimport { NodeItem, Parsed, Parser, Tokenizer } from 'models'\n\ntype ParsersList = { parser: Parser, priority: number }[]\n\nconst MDJ = () => {\n  const parsers: {\n    block: ParsersList\n    inline: ParsersList\n  } = {\n    block: [\n      { parser: captureNewLine, priority: 1000 },\n      { parser: captureHeading, priority: 900 },\n      { parser: captureHR, priority: 800 },\n      { parser: captureBlockquote, priority: 700 },\n      { parser: captureCodeBlock, priority: 600 },\n      { parser: captureTable, priority: 500 },\n      { parser: captureList, priority: 400 },\n      { parser: captureHTML, priority: 300 },\n      { parser: captureParagraph, priority: 0 }\n    ],\n    inline: [\n      { parser: captureEscape, priority: 1000 },\n      { parser: captureCode, priority: 900 },\n      { parser: captureStrong, priority: 800 },\n      { parser: captureEm, priority: 700 },\n      { parser: captureStrikethrough, priority: 600 },\n      { parser: captureLinks, priority: 500 },\n      { parser: captureLineBreak, priority: 400 },\n      { parser: captureText, priority: 0 }\n    ]\n  }\n\n  const blockLexer: Tokenizer = lexer('block')\n  const inlineLexer: Tokenizer = lexer('inline')\n\n  function addParser (type: 'block' | 'inline', parser: Parser, priority: number) {\n    parsers[type].push({parser, priority})\n    parsers[type] = parsers[type].sort((a, b) => b.priority - a.priority)\n  }\n\n  function pinchToken (type: 'block' | 'inline', source: string): Parsed<NodeItem> | null {\n    const l = parsers[type].length\n    let token\n    let newSource = ''\n\n    for (let i = 0; i < l; i += 1) {\n      const parser = parsers[type][i].parser\n      const parsed = type === 'block' ?\n        parser(source, blockLexer, inlineLexer) :\n        parser(source, inlineLexer)\n\n      if (parsed) {\n        newSource = parsed.newSource\n        token = parsed.token\n        break\n      }\n    }\n\n    if (!token) {\n      return null\n    }\n\n    return {\n      token,\n      newSource\n    }\n  }\n\n  function lexer (type: 'block' | 'inline') {\n    return (source: string): NodeItem[] => {\n      const tokens: NodeItem[] = []\n\n      while (source.length > 0) {\n        const {token = null, newSource = ''} = pinchToken(type, source) || {}\n\n        if (source === newSource || !token) {\n          throw new Error('Infinite loop on byte: ' + source.charCodeAt(0))\n        }\n\n        tokens.push(token)\n        source = newSource\n      }\n\n      return tokens\n    }\n  }\n\n  function prepareSource(source: string) {\n    return clearSource(source)\n  }\n\n  return {\n    parse: function parse(source: string) {\n      return blockLexer(prepareSource(source))\n    },\n    useInlineParser: function useInlineParser(parser: Parser, priority: number) {\n      addParser('inline', parser, priority)\n      return this\n    },\n    useBlockParser: function useBlockParser(parser: Parser, priority: number) {\n      addParser('block', parser, priority)\n      return this\n    }\n  }\n}\n\nexport { MDJ }\n","import { MDJ } from 'core/MDJ'\n\nconst parse = (source: string) => MDJ()\n  .parse(source)\n\nexport default MDJ\nexport { parse }\n"],"names":["curry","fn","arguments","length","inner","args","Array","prototype","slice","call","apply","bind","concat","clearSource","input","replace","compose","fns","l","arg","result","i","exec","a","b","regExp","map","match","matches","withWhat","what","test","from","to","split","trim","where","indexOf","source","execBlockquote","clearBlockquote","captureBlockquote","tokenize","capture","children","type","token","newSource","substring","execCodeNormal","clearCode","execCodeFence","captureCodeNormal","language","value","captureCodeFence","captureCodeBlock","execHeading","execLHeading","getLevel","captureHeading","_","inlineLexer","isNormal","level","rawValue","execHR","captureHR","execHTML","captureHTML","execList","matchItems","removeBullets","removeSpaces","matchBullet","precedeList","captureList","bull","parseChild","topItemsParsed","item","itemChildren","startToken","ordered","start","execNewLine","captureNewLine","execParagraph","removeLastLineBreak","captureParagraph","removeHeaderBounds","removeCellBounds","removeRowBounds","removeLastBounds","splitByLineBreak","isRight","isCenter","splitRow","cell","getTableHeader","lexer","getTableRow","getCellAlign","getTableAlign","getNormalCells","cells","getNPCells","execNPTable","execTableNormal","captureTable","isNP","header","align","execCode","captureCode","execEm","captureEm","execEscape","captureEscape","execLineBreak","captureLineBreak","execAutolink","captureAutolink","at","text","href","charAt","testUrlStart","execUrl","captureUrl","execLink","captureLink","title","src","alt","captureLinks","execStrikethrough","captureStrikethrough","execStrong","captureStrong","execText","captureText","MDJ","parser","priority","parsers","push","sort","parsed","blockLexer","tokens","_a","_b","_c","Error","charCodeAt","block","inline","parse","prepareSource","useInlineParser","addParser","this","useBlockParser"],"mappings":"oMA6CA,IAAMA,GAAe,WACnB,GAAMC,GAAeC,UAAU,GACzBC,EAASF,EAAGE,OAEZC,EAAQ,WACZ,GAAIC,GAAOC,MAAMC,UAAUC,MAAMC,KAAKP,UAEtC,OAAIG,GAAKF,QAAUA,EACVF,EAAGS,MAAM,KAAML,GAEfD,EAAMO,KAAKD,MAAMN,GAAQ,MAAMQ,OAAOP,IAIjD,OAAOD,GAAMO,KAAKD,MAAMN,GAAQ,MAAMQ,OAAON,MAAMC,UAAUC,MAAMC,KAAKP,UAAW,MC3D/EW,EAAc,SAACC,GAAkB,MAAAA,GAAMC,QAAQ,WAAY,MAC9DA,QAAQ,MAAO,QACfA,QAAQ,UAAW,KACnBA,QAAQ,UAAW,MACnBA,QAAQ,SAAU,KCsBfC,EAAmB,WACvB,GAAMC,GAAMX,MAAMC,UAAUC,MAAMC,KAAKP,WACjCgB,EAAID,EAAId,OAAS,CAEvB,OAAO,UAASgB,GAGd,IAAK,GAFDC,GAASD,EAEJE,EAAIH,EAAGG,GAAK,EAAGA,GAAK,EAC3BD,EAASH,EAAII,GAAGD,EAGlB,OAAOA,KCnCLE,GCAStB,EAAM,SAACuB,EAAQC,GAAoB,MAAAD,KAAMC,IDA3CxB,EAAM,SAACyB,EAAgBX,GAAmC,MAAAW,GAAOH,KAAKR,MEK7EY,EAAW1B,EAAM,SAAOC,EAAwCa,GAGpE,IAAK,GAFCM,GAAS,GAAId,OAAMQ,EAAMX,QAEtBkB,EAAI,EAAGA,EAAIP,EAAMX,OAAQkB,GAAK,EACrCD,EAAOC,GAAKpB,EAAGa,EAAMO,GAAIA,EAAGP,EAG9B,OAAOM,KCZHO,EAAQ3B,EAAM,SAACyB,EAAgBX,GAAkB,MAAAA,GAAMa,MAAMF,SCA7DG,EAAU5B,EAAM,SAAC6B,EAAkBC,GAAiB,MAAAD,GAASE,KAAKD,KCAlEf,EAAUf,EAAM,SAACgC,EAAuBC,EAAYnB,GAAkB,MAAAA,GAAMC,QAAQiB,EAAMC,KCA1FC,EAAQlC,EAAM,SAACyB,EAAyBX,GAA4B,MAAAA,GAAMoB,MAAMT,KCFhFU,GCEanC,EAAM,SAAC8B,EAAcM,GAAkB,MAAwB,KAAxBA,EAAMC,QAAQP,KDF3D,SAACQ,GAAmB,MAAAA,GAAOH,SEIlCI,EAAiBjB,EAAK,mGACtBkB,EAAkBzB,EAAQ,WAAY,IACtC0B,EAAoB,SAACH,EAAgBI,GACzC,GAAkB,MAAdJ,EAAO,GACT,MAAO,KAGT,IAAMlB,GAASmB,EAAeD,EAE9B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GAEnBwB,EAAWF,EAASF,EAAgBG,GAMxC,OAJwB,KAApBC,EAASzC,QAAqC,cAArByC,EAAS,GAAGC,OACvCD,EAAYA,EAAS,GAAqBA,WAI1CE,OACED,KAAM,aACND,SAAUF,EAASF,EAAgBG,KAErCI,UAAWT,EAAOU,UAAUL,EAAQxC,UC1BlC8C,EAAiB3B,EAAK,qBACtB4B,EAAYnC,EAAQ,UAAW,IAC/BoC,EAAgB7B,EAAK,8DAErB8B,EAAoB,SAACd,GACzB,GAAkB,MAAdA,EAAO,GACT,MAAO,KAGT,IAAMlB,GAAS6B,EAAeX,EAE9B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAEvB,QACE0B,OACED,KAAM,YACNQ,SAAU,GACVC,MAAOJ,EAAUP,IAEnBI,UAAWT,EAAOU,UAAUL,EAAQxC,UAIlCoD,EAAmB,SAACjB,GACxB,GAAMlB,GAAS+B,EAAcb,EAE7B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAIvB,QACE0B,OACED,KAAM,YACNQ,SANajC,EAAO,GAOpBkC,MANUlC,EAAO,IAQnB2B,UAAWT,EAAOU,UAAUL,EAAQxC,UAIlCqD,EAAmB,SAAClB,GACxB,MAAAc,GAAkBd,IAAWiB,EAAiBjB,ICjD1CmB,EAAcnC,EAAK,yCACnBoC,EAAepC,EAAK,sCACpBqC,EAAW,SAAC7C,GAChB,MAAiB,MAAbA,EAAM,GACDA,EAAMX,OAGK,MAAbW,EAAM,GAAa,EAAI,GAG1B8C,EAAiB,SAACtB,EAAgBuB,EAAQC,GAC9C,GAAMC,GAAyB,MAAdzB,EAAO,GAClBlB,EAAU2C,GAAYN,EAAYnB,IAAYoB,EAAapB,EAEjE,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjB4C,EAAQD,EAAW3C,EAAO,GAAKA,EAAO,GACtC6C,EAAWF,EAAW3C,EAAO,GAAKA,EAAO,EAE/C,QACE0B,OACED,KAAM,UACNmB,MAAOL,EAASK,GAChBpB,SAAUkB,EAAYG,IAExBlB,UAAWT,EAAOU,UAAUL,EAAQxC,UC5BlC+D,EAAS5C,EAAK,wCAEd6C,EAAY,SAAC7B,GACjB,GAAMlB,GAAS8C,EAAO5B,EAEtB,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAEvB,QACE0B,OAASD,KAAM,MACfE,UAAWT,EAAOU,UAAUL,EAAQxC,UCblCiE,EAAW9C,EAAK,obAEhB+C,EAAc,SAAC/B,GACnB,GAAkB,MAAdA,EAAO,GACT,MAAO,KAGT,IAAMlB,GAASgD,EAAS9B,EAExB,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAEvB,QACE0B,OACED,KAAM,OACNS,MAAOX,GAETI,UAAWT,EAAOU,UAAUL,EAAQxC,UCnBlCmE,EAAWhD,EAAK,2LAChBiD,EAAa5C,EAAM,sEACnB6C,EAAgBzD,EAAQ,qBAAsB,IAC9C0D,EAAe1D,EAAQ,QAAS,IAChC2D,EAAc/C,EAAM,SACpBgD,EAAc5D,EAAQ,eAAgB,QAEtC6D,EAAc,SAACtC,EAAgBI,GACnC,GAAMtB,GAASkD,EAAShC,EAExB,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjByD,EAAOzD,EAAO,GAEd0D,EAAa9D,EAAQ0B,EAAUiC,EAAaF,EAAcD,GAC1DO,EAAiBR,EAAW5B,GAASjB,IAAI,SAACsD,GAC9C,GAAIC,GAAeH,EAAWE,EAM9B,OAJ4B,KAAxBC,EAAa9E,QAAyC,cAAzB8E,EAAa,GAAGpC,OAC/CoC,EAAgBA,EAAa,GAAqBrC,WAIlDC,KAAM,WACND,SAAUqC,KAIRC,EAAaR,EAAYG,EAQ/B,QACE/B,OAPAD,KAAM,OACNsC,UAAWD,EACXE,MAAOF,IAAeA,EAAW,GACjCtC,SAAUmC,GAKVhC,UAAWT,EAAOU,UAAUL,EAAQxC,UC1ClCkF,EAAc/D,EAAK,QAEnBgE,EAAiB,SAAChD,GACtB,GAAMlB,GAASiE,EAAY/C,EAE3B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAEvB,QACE0B,OAASD,KAAM,SACfE,UAAWT,EAAOU,UAAUL,EAAQxC,UCblCoF,EAAgBjE,EAAK,wBACrBkE,EAAsBzE,EAAQ,MAAO,KAErC0E,EAAmB,SAACnD,EAAgBuB,EAAQC,GAChD,GAAM1C,GAASmE,EAAcjD,EAE7B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjB6C,EAAW7C,EAAO,EAExB,QACE0B,OACED,KAAM,YACND,SAAUkB,EAAY0B,EAAoBvB,KAE5ClB,UAAWT,EAAOU,UAAUL,EAAQxC,UCjBlCuF,EAAqB3E,EAAQ,eAAgB,IAC7C4E,EAAmB5E,EAAQ,mBAAoB,IAC/C6E,EAAkB7E,EAAQ,aAAc,IACxCyE,EAAsBzE,EAAQ,MAAO,KACrC8E,EAAmB9E,EAAQ,iBAAkB,IAC7C+E,EAAmB5D,EAAM,MACzB6D,EAAUnE,EAAQ,aAClBoE,EAAWpE,EAAQ,cAEnBqE,EAAW,SAACnF,GAIhB,IAAI,GAHEM,MACF8E,EAAO,EAEH7E,EAAI,EAAGA,EAAIP,EAAMX,OAAQkB,GAAK,EACnB,MAAbP,EAAMO,IAA+B,MAAjBP,EAAMO,EAAI,IAA+B,OAAjBP,EAAMO,EAAI,GAI1DD,EAAO8E,IAAS9E,EAAO8E,IAAS,IAAMpF,EAAMO,GAH1C6E,GAMJ,OAAOxE,GAAIS,EAAMf,IAGb+E,EAAiB,SAACC,EAAkB9D,GACxC,MAAAtB,GAAQU,EAAI0E,GAAQH,EAAUP,GAAoBpD,IAC9C+D,EAAcrF,EAAQiF,EAAUN,GAChCW,EAAe,SAACxF,GACpB,MAAIiF,GAAQjF,GACH,QACEkF,EAASlF,GACX,SAEA,QAGLyF,EAAgBvF,EAAQU,EAAI4E,GAAepE,EArClC,UAqCiD0D,GAC1DY,EAAiB,SAACJ,EAAkBK,GACxC,MAAAzF,GAAQU,EAAIV,EAAQU,EAAI0E,GAAQC,IAAeP,EAAkBD,GAAkBY,IAC/EC,GAAa,SAACN,EAAkBK,GACpC,MAAAzF,GAAQU,EAAIV,EAAQU,EAAI0E,GAAQlE,EAzCnB,YAyCoC4D,EAAkBN,GAAqBiB,IAEpFE,GAAcrF,EAAK,iEACnBsF,GAAkBtF,EAAK,6DAEvBuF,GAAe,SAACvE,EAAgBuB,EAAQC,GAC5C,GAAI1C,GAASuF,GAAYrE,GACrBwE,GAAO,CAOX,IALK1F,IACHA,EAASwF,GAAgBtE,GACzBwE,GAAO,IAGJ1F,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjB2F,EAAS3F,EAAO,GAChB4F,EAAQ5F,EAAO,GACfqF,EAAQrF,EAAO,EAErB,OAAKuB,IAKHG,OACED,KAAM,QACNkE,OAAQZ,EAAerC,EAAaiD,GACpCC,MAAOT,EAAcS,GACrBP,MAAOK,EAAOJ,GAAW5C,EAAa2C,GAASD,EAAe1C,EAAa2C,IAE7E1D,UAAWT,EAAOU,UAAUL,EAAQxC,SAV7B,MCjEL8G,GAAW3F,EAAK,oCAChB4F,GAAc,SAAC5E,GACnB,GAAkB,MAAdA,EAAO,GACP,MAAO,KAGX,IAAMlB,GAAS6F,GAAS3E,EAExB,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAGvB,QACE0B,OACED,KAAM,OACNS,MALSlC,EAAO,IAOlB2B,UAAWT,EAAOU,UAAUL,EAAQxC,UCpBlCgH,GAAS7F,EAAK,yDACd8F,GAAY,SAAC9E,EAAgBwB,GACjC,GAAkB,MAAdxB,EAAO,IAA4B,MAAdA,EAAO,GAC5B,MAAO,KAGX,IAAMlB,GAAS+F,GAAO7E,EAEtB,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjBG,EAAIH,EAAO,EAGjB,QACE0B,OACED,KAAM,KACND,SAAUkB,EALJ1C,EAAO,IAKcG,IAE7BwB,UAAWT,EAAOU,UAAUL,EAAQxC,UCrBlCkH,GAAa/F,EAAK,gCAClBgG,GAAgB,SAAChF,GACrB,GAAkB,OAAdA,EAAO,GACP,MAAO,KAGX,IAAMlB,GAASiG,GAAW/E,EAE1B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAEvB,QACE0B,OACED,KAAM,OACNS,MAAOX,GAETI,UAAWT,EAAOU,UAAUL,EAAQxC,UCnBlCoH,GAAgBjG,EAAK,iBACrBkG,GAAmB,SAAClF,GACxB,GAAMlB,GAASmG,GAAcjF,EAE7B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAEvB,QACE0B,OACED,KAAM,MAERE,UAAWT,EAAOU,UAAUL,EAAQxC,UCdlCsH,GAAenG,EAAK,4BACpBoG,GAAkB,SAACpF,GACvB,GAAkB,MAAdA,EAAO,GACT,MAAO,KAGT,IAAMlB,GAASqG,GAAanF,EAE5B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjBuG,EAAKvG,EAAO,GACdwG,EAAOxG,EAAO,GACdyG,EAAO,EAUX,OAPW,MAAPF,GACFC,EAA0B,MAAnBA,EAAKE,OAAO,GAAaF,EAAK5E,UAAU,GAAK4E,EACpDC,EAAO,UAAYD,GAEnBC,EAAOD,GAIP9E,OACED,KAAM,OACNgF,OACAjF,WAEIC,KAAM,OACNS,MAAOsE,KAIb7E,UAAWT,EAAOU,UAAUL,EAAQxC,UAIlC4H,GAAenG,EAAQ,SACvBoG,GAAU1G,EAAK,wCACf2G,GAAa,SAAC3F,GAClB,IAAKyF,GAAazF,GAChB,MAAO,KAGT,IAAMlB,GAAS4G,GAAQ1F,EAEvB,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjBwG,EAAOxG,EAAO,EAEpB,QACE0B,OACED,KAAM,OACNgF,KAAMD,EACNhF,WAEIC,KAAM,OACNS,MAAOsE,KAIb7E,UAAWT,EAAOU,UAAUL,EAAQxC,UAKlC+H,GAAW5G,EAAK,mGAChB6G,GAAc,SAAC7F,EAAgBwB,GACnC,GAAkB,MAAdxB,EAAO,IAA4B,MAAdA,EAAO,GAC9B,MAAO,KAGT,IACIQ,GADE1B,EAAS8G,GAAS5F,EAGxB,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjBwG,EAAOxG,EAAO,GACdyG,EAAOzG,EAAO,GACdgH,EAAQhH,EAAO,EAoBrB,OAjBE0B,GADc,MAAZ8E,EAAK,IAEL/E,KAAM,QACNwF,IAAKR,EACLS,IAAKV,IAIL/E,KAAM,OACNgF,OACAjF,SAAUkB,EAAY8D,IAItBQ,IACFtF,EAAMsF,MAAQA,IAIdtF,QACAC,UAAWT,EAAOU,UAAUL,EAAQxC,UAKlCoI,GAAe,SAACjG,EAAgBwB,GACpC,MAAA4D,IAAgBpF,IAAW2F,GAAW3F,IAAW6F,GAAY7F,EAAQwB,ICpHjE0E,GAAoBlH,EAAK,2BACzBmH,GAAuB,SAACnG,EAAgBwB,GAC5C,GAAkB,MAAdxB,EAAO,GACP,MAAO,KAGX,IAAMlB,GAASoH,GAAkBlG,EAEjC,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAGvB,QACE0B,OACED,KAAM,gBACND,SAAUkB,EALG1C,EAAO,KAOtB2B,UAAWT,EAAOU,UAAUL,EAAQxC,UCpBlCuI,GAAapH,EAAK,kDAClBqH,GAAgB,SAACrG,EAAgBwB,GACrC,GAAkB,MAAdxB,EAAO,IAA4B,MAAdA,EAAO,GAC5B,MAAO,KAGX,IAAMlB,GAASsH,GAAWpG,EAE1B,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,GACjBG,EAAIH,EAAO,EAGjB,QACE0B,OACED,KAAM,SACND,SAAUkB,EALJ1C,EAAO,IAKcG,IAE7BwB,UAAWT,EAAOU,UAAUL,EAAQxC,UCrBlCyI,GAAWtH,EAAK,+CAEhBuH,GAAc,SAACvG,GACnB,GAAMlB,GAASwH,GAAStG,EAExB,KAAKlB,EACH,MAAO,KAGT,IAAMuB,GAAUvB,EAAO,EAEvB,QACE0B,OACED,KAAM,OACNS,MAAOX,GAETI,UAAWT,EAAOU,UAAUL,EAAQxC,UCQlC2I,GAAM,WA+BV,WAAoBjG,EAA0BkG,EAAgBC,GAC5DC,EAAQpG,GAAMqG,MAAMH,SAAQC,aAC5BC,EAAQpG,GAAQoG,EAAQpG,GAAMsG,KAAK,SAAC5H,EAAGC,GAAM,MAAAA,GAAEwH,SAAWzH,EAAEyH,WAG9D,WAAqBnG,EAA0BP,GAK7C,IAAK,GAHDQ,GADE5B,EAAI+H,EAAQpG,GAAM1C,OAEpB4C,EAAY,GAEP1B,EAAI,EAAGA,EAAIH,EAAGG,GAAK,EAAG,CAC7B,GAAM0H,GAASE,EAAQpG,GAAMxB,GAAG0H,OAC1BK,EAAkB,UAATvG,EACbkG,EAAOzG,EAAQ+G,EAAYvF,GAC3BiF,EAAOzG,EAAQwB,EAEjB,IAAIsF,EAAQ,CACVrG,EAAYqG,EAAOrG,UACnBD,EAAQsG,EAAOtG,KACf,QAIJ,MAAKA,IAKHA,QACAC,aALO,KASX,WAAgBF,GACd,MAAO,UAACP,GAGN,IAFA,GAAMgH,MAEChH,EAAOnC,OAAS,GAAG,CAClB,GAAAoJ,cAACC,UAAA1G,oBAAc2G,cAAA1G,iBAErB,IAAIT,IAAWS,IAAcD,EAC3B,KAAM,IAAI4G,OAAM,0BAA4BpH,EAAOqH,WAAW,GAGhEL,GAAOJ,KAAKpG,GACZR,EAASS,EAGX,MAAOuG,IAIX,WAAuBhH,GACrB,MAAOzB,GAAYyB,GAnFrB,GAAM2G,IAIJW,QACIb,OAAQzD,EAAgB0D,SAAU,MAClCD,OAAQnF,EAAgBoF,SAAU,MAClCD,OAAQ5E,EAAW6E,SAAU,MAC7BD,OAAQtG,EAAmBuG,SAAU,MACrCD,OAAQvF,EAAkBwF,SAAU,MACpCD,OAAQlC,GAAcmC,SAAU,MAChCD,OAAQnE,EAAaoE,SAAU,MAC/BD,OAAQ1E,EAAa2E,SAAU,MAC/BD,OAAQtD,EAAkBuD,SAAU,IAExCa,SACId,OAAQzB,GAAe0B,SAAU,MACjCD,OAAQ7B,GAAa8B,SAAU,MAC/BD,OAAQJ,GAAeK,SAAU,MACjCD,OAAQ3B,GAAW4B,SAAU,MAC7BD,OAAQN,GAAsBO,SAAU,MACxCD,OAAQR,GAAcS,SAAU,MAChCD,OAAQvB,GAAkBwB,SAAU,MACpCD,OAAQF,GAAaG,SAAU,KAI/BK,EAAwBjD,EAAM,SAC9BtC,EAAyBsC,EAAM,SA0DrC,QACE0D,MAAO,SAAexH,GACpB,MAAO+G,GAAWU,EAAczH,KAElC0H,gBAAiB,SAAyBjB,EAAgBC,GAExD,MADAiB,GAAU,SAAUlB,EAAQC,GACrBkB,MAETC,eAAgB,SAAwBpB,EAAgBC,GAEtD,MADAiB,GAAU,QAASlB,EAAQC,GACpBkB,QC3HPJ,GAAQ,SAACxH,GAAmB,MAAAwG,MAC/BgB,MAAMxH"}